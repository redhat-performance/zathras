#!/bin/bash
#                         License
#
# Copyright (C) 2022  David Valin dvalin@redhat.com
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
# burden is part of the Zathras automation framework.  Burden has 2 operation modes
#  Mode 1: Reads in the scenario file, parses the arguments and then calls back
#          onto itself with the parsed arguments.
#  Mode 2: Takes the list of arguments and generates the required yml files for
#          ansible to use.  Once the yml files are generated, burden will then invoke
#          the test.
#

# Burdens version number.

cli=${0}
arguments=("$@")
version="3.2"
export ANSIBLE_ROLES_PATH=$HOME/.ansible/collections/ansible_collections/pbench/agent/roles:$ANSIBLE_ROLES_PATH
#
# This bash script generates the test parameters to be used by ansible. End results
# is an ansible data file called ansible_vars_main.yml containing the following
# ---
# config_info:
#   hostname_file: Points to the directory where we will record the VM hostname,
#                  used for deleting the entry from the proper ssh config file
#                  when the test is done.
#   local_run_dir: Top level directory to be running from.
#   gl_system_type:  Name of the cloud vendor we are using.  local is a special name,
#                  indicating not a cloud system.
#   gl_host_config: m5.xlarge
#   gl_host_config_info: m5.xlarge
#   host_or_cloud_inst: m5.xlarge
#   gl_selinux_level: state of selinux
#     enforcing - SELinux security policy is enforced.
#     permissive - SELinux prints warnings instead of enforcing.
#   gl_selinux_state: state of selinux
#     enabled - SELinux security policy is active.
#     disabled - No SELinux policy is loaded.
#   gl_cloud_os_version: Cloud specific, indicates what OS version we are to load.
#   gl_test_repos: Where we will find the tests to use.
#   force_upload: Used when just creating a cloud image.  Will force all packages
#                 to be uploaded.
#   gl_cloud_terminate_instance: Terminate the cloud image when we are done
#   update_os_version: pointer to the OS update location
#   update_type: what is the update repository (example ftp, iso).
#   gl_persistent_log: enable persistent logging
#   gl_ssh_key_file: Points to the ssh config file we are to use.  If not set, we will not use one.
#   gl_java_version: Version of Java to load:  eg: java-8 or java-11
#   gl_rhel_tuned_setting: tuned configuration to use
#   gl_cloud_execute_tests: If set to 1, we will execute test on the cloud image, else
#                        we will simply create the image.
#   pbench_disk_required: If set to 1, we need a disk for pbench
#   gl_os_vendor: Who is the OS provider (rhel, ubuntu, amazon)
#   storage_required: is storage required?
#   network_required: is a network required?
#   gl_cloud_region: What region to create the cloud image in
#   cloud_delete_region: Region deleting the cloud image from, mainly gl_cloud_region minus the zone (AWS only)
#   cloud_number_disk: How many disks we are to create
#   gl_host_uses_nvme: Does the host represent its drives as /dev/nvme* or /dev/sd*
#   cloud_numb_networks: Number of networks we are creating
#   test_iterations: How many times are we to run the test.  Each iteration is a full run of the tests,
#                    deletion of the cloud image, and recreation of the cloud image.
#   user_parent_home_dir: Parent home directory of the user executing the tests (who is logged into the 
#                         test system).
#   user_running: Who is running Zathras
#   test_user: User name that is executing the test on the test system (ec2-user, root etc)
#   pbench_install: Do we need to install pbench?
#

#
# Global values specific to the configuration.
#   host_uses_nvme: is the disk expected to be nvme
#   cloud_region: region to create the instance in.
#   gl_cloud_region_zone: zone to create the instance in.
#
value_not_set="none"
gl_sys_index_rerun=1
gl_kit_upload_directory="none"
gl_retry_failed_tests=1
gl_base_cost=0
gl_host_uses_nvme=0
gl_cloud_net_type="default"
#
# We will default to eastus
#
gl_cloud_acct_id=""
gl_cloud_region="eastus"
gl_cloud_region_zone=""
gl_system_type=""
gl_first_invocation=1
gl_use_spot=0
gl_spot_price=0
gl_spot_cap="0"
gl_spot_increment="0"
gl_git_timeout=60
gl_git_timeout_set=0
gl_archive_location=$value_not_set
gl_error_repo_errors=1
gl_valid_os_vendors="rhel ubuntu amazon private none"
gl_valid_system_types="aws azure gcp local"
gl_package_name=$value_not_set
gl_show_tests=0
gl_create_attempts=5
gl_spot_recover=1
gl_cloud_placement=${value_not_set}
gl_cloud_networks_sys="duplicate"
gl_preflight=0
#
# Global values
#   gl_sys_file: sysctl files to use.
#   gl_cloud_execute_tests: If set to 1, will execute the test, else will not
#   gl_install_pbench:  Does pbench need to be installed
#   gl_test_repos: where to find the test repository (git)
#   gl_image_type: what is the OS image type we are using for update (ftp/iso).
#   disk_present: are disks requested.
#   gl_networks_present: are networks requested.
#   gl_internal_disk: disk is internal to the system.
#   gl_top_dir: Directory we are executing from
#
gl_tf_terminate=0
gl_tf_term_list=""
gl_tf_list=0
gl_sys_file=$value_not_set
gl_cloud_execute_tests=1
gl_install_pbench=0
gl_test_repos=""
gl_image_type=""
gl_disks_present=0
gl_networks_present=0
gl_internal_disks=0
gl_top_dir=`pwd`
#
# initialize arguments
#
gl_cloud_force_upload=0
gl_cloud_force_upload_set=0
gl_cloud_os_version=""
gl_cloud_terminate_instance=1
gl_cloud_terminate_instance_set=0
gl_create_only=0
gl_disks_asking_for=""
gl_disk_cloud_index=1
gl_host_config=""
gl_host_config_info=""
gl_java_version=$value_not_set
gl_os_vendor=$value_not_set
gl_persistent_log=0
gl_run_dir_index=0
gl_run_prefix=""
gl_scenario_to_run=""
gl_scenario_to_restore=""
gl_selinux_level="enforcing"
gl_selinux_state="enabled"
gl_selinux_state_set=0
gl_ssh_key_file=""
gl_show_os_versions=0;
gl_test_def_file=""
gl_test_def_dir="${gl_top_dir}/config"
gl_test_def_dir_set=0
gl_test_iterations=1
gl_test_iterations_set=0
gl_test_list=""
gl_test_list_out="--tests "
gl_rhel_tuned_setting=$value_not_set
gl_rhel_tuned_reboot=0
gl_update_target=$value_not_set
gl_upload_rpms=$value_not_set
gl_cli_supplied_options=""
gl_test_override_options=""
gl_warning_string=""
gl_max_systems=3
gl_max_systems_set=0
#
# We want the version check on.  We do this, as no options to burden
# should provide a usage.  The --test_version_check option is present
# so we can only check the versions via an option
#
gl_test_version_check=1
gl_update_test_versions=0
gl_disk_iops=0
gl_disk_tp=0
gl_no_clean_up=0
gl_cloud_number_disks=0
gl_config_vars_file="config/zathras_scenario_vars_def"
gl_config_vars_file_set=0
gl_moved_scenario="no"
gl_cloud_disk_type=""
gl_zathras_specific_vals="config/zathras_specific_vals_def"
gl_zathras_specific_vals_set=0
gl_no_packages=0
gl_no_pbench_install=0
gl_pbench_stats="medium"
gl_cpu_type_request="none"
gl_run_file=""
gl_failed_test_rpt="failed_tests"

#
# We get the number of failed test reports at the start of the test.  When we exit we will
# check the original number of reported failed tests to what we currently have.  If they
# are different then we will report failed for the run.  This is done because burden calls
# back onto itself
if [[ -f $gl_failed_test_rpt ]]; then
	gl_failed_test_rpt_start_lines=`wc -l $gl_failed_test_rpt | awk '{print $1}'`
else
	gl_failed_test_rpt_start_lines=0
fi
gl_test_user=""

UTILS_DIR=`echo $BASH_SOURCE | rev | cut -d/ -f2- | rev`
echo $UTILS_DIR | grep -q "^/"
if [ $? -ne 0 ]; then
	curdir=`pwd`
	UTILS_DIR=${curdir}/$UTILS_DIR/utils
else
	UTILS_DIR=$UTILS_DIR/utils
fi

#
# Generate report of test status.
# 
process_results()
{
	if [ $gl_first_invocation -eq 1 ]; then
		sort -u run_info > run_info.sorted
		while IFS= read -r run_data
		do
			pushd $gl_top_dir/$run_data >& /dev/null
			$gl_top_dir/tools_bin/determine_test_status
			grep failed initial_summary > $gl_top_dir/failures
			$gl_top_dir/tools_bin/report_missing_failed_test
			if [[ $? -ne 0 ]] && [[ $gl_retry_failed_tests -eq 1 ]]; then
				handle_error_reruns
			fi
			popd  >& /dev/null
		done < "run_info.sorted"
	fi
}

#
# We call in here for cleanup purpose, then exit out
# Arg1: Message string
# Arg2: The exit code
# Arg3: If present instance name
#

cleanup_and_exit()
{
	scenario_restore=""
	sysname=""
	rtc=$2
	if [[ $gl_scenario_to_restore != "" ]]; then
		scenario_restore="--restore_file $gl_scenario_to_restore,$gl_scenario_to_run"
	fi
	if [[ $3 != "" ]]; then
		sysname="--sysname $3"
	fi
	cd $gl_top_dir
	#
	# We only check the failed report file if this is the burden process that
	# started it all.
	#
	if [ $gl_first_invocation -eq 1 ] && [[ -f $gl_failed_test_rpt ]]; then
		new_lines=`wc -l $gl_failed_test_rpt | awk '{print $1}'`
		if  [ $new_lines -ne $gl_failed_test_rpt_start_lines ]; then
			rtc=1
		fi
	fi
	source $UTILS_DIR/cleanup_and_exit_out --fail_report $gl_failed_test_rpt --msg_string "$1" --rtc $rtc --pid $BASHPID $scenario_restore $sysname --top_dir $gl_top_dir
}

make_dir_report_errors()
{
	mkdir -p $1 2> /dev/null
	if [ $? -ne 0 ]; then
		cleanup_and_exit "Error Unable to make the directory $1"
	fi
}

#
# Show the OS versions available for azure for a specific OS vendor.
#
azure_image_lookup()
{
	if [[ $gl_os_vendor == "ubuntu" ]]; then
		publisher=Canonical
	elif [[ $gl_os_vendor == "rhel" ]]; then
		publisher=RedHat
	else
		cleanup_and_exit "Unknown os vendor $gl_os_vendor, valid types are ubuntu, rhel" 1 ${gl_system_type}
	fi
	echo "Pulling requested Azure OS image information, may take a bit."
	end_date=`date +"%Y"`
	let "start_date=$end_date-1"
	az vm image list --all --publisher $publisher --output tsv | egrep ".$start_date|.$end_date"
	cleanup_and_exit "" 0
}

#
# Show the OS versions available for gcp for a specific OS vendor.
#
gcp_image_lookup()
{
	if [[ $gl_os_vendor == "ubuntu" ]]; then
		project="ubuntu-os-cloud"
	elif [[ $gl_os_vendor == "rhel" ]]; then
		project="rhel-cloud"
	else
		cleanup_and_exit "Unknown os vendor $gl_os_vendor, valid types are ubuntu, rhel" 1 ${gl_system_type}
	fi
	echo "Pulling requested GCP OS image information, may take a bit."
	end_date=`date +"%Y"`
	let "start_date=$end_date-1"
	gcloud compute images list --format="table(NAME,PROJECT,creationTimestamp.date(tz=LOCAL))" | grep "$project" | egrep ".$start_date|.$end_date"
	cleanup_and_exit "" 0
}

get_cloud_acct_id()
{
	if [[ $gl_cloud_acct_id == "" ]]; then
		if [[ $gl_system_type == "aws" ]]; then
			gl_cloud_acct_id=`aws sts get-caller-identity | awk '{print $1}'`
		else
			cleanup_and_exit "$gl_system_type:  Do not support pulling account id at this time" 1
		fi
	fi
}

#
# Show the OS versions available for AWS for a specific OS vendor.
#
show_aws_images()
{
	if [[ $gl_os_vendor == "ubuntu" ]]; then
		filter="Name=name,Values=ubuntu*"
	elif [[ $gl_os_vendor == "rhel" ]]; then
		filter="Name=name,Values=RHEL*"
	elif [[ $gl_os_vendor == "amazon"  ]]; then
		filter="Name=name,Values=amz*,al2023*"
	elif [[ $gl_os_vendor != "private"  ]]; then
		cleanup_and_exit "Unknown os vendor $gl_os_vendor, valid types are ubuntu, rhel, amazon, private" 1 ${gl_system_type}
	fi
	end_date=`date +"%Y"`
	let "start_date=$end_date-1"
	if [[ $2 -eq 0 ]]; then
		echo "Pulling requested AWS OS image information, may take a bit."
		if [[ $gl_os_vendor != "private" ]]; then
			aws ec2 describe-images --query 'sort_by(Images, &CreationDate)[*].[CreationDate,Name,ImageId]' --filters "$filter" --output table | egrep "${start_date}|${end_date}"
		else
			get_cloud_acct_id
			aws ec2 describe-images --owners $gl_cloud_acct_id --output table --query 'sort_by(Images, &CreationDate)[*].[CreationDate,Name,ImageId]'
		fi
		cleanup_and_exit "" 0
	fi
	#
	# Verify the ami we are using is valid.
	#
	work_with=`echo $gl_cloud_os_version | sed "s/,/ /g"`
	for ami in $work_with; do
		if [[ $ami == *":"* ]]; then
			ami_check=`echo $ami | cut -d':' -f2`
			ami_arch=`echo $ami | cut -d':' -f1`
		else
			ami_check=$ami
			ami_arch=""
		fi
		ami_value=`aws ec2 describe-images --query 'sort_by(Images, &CreationDate)[*].[CreationDate,Name,ImageId]' --filters "$filter" --output table | egrep "${start_date}|${end_date}" | grep "${ami_check}"`
		if [[ $ami_value != "" ]]; then
			#
			# check_for_private_amis
			#
			get_cloud_acct_id
			ami_value=`aws ec2 describe-images --owners $gl_cloud_acct_id --output table --query 'sort_by(Images, &CreationDate)[*].[CreationDate,Name,ImageId]' | grep "${ami_check}"`
			if [[ $ami_value != "" ]]; then
				cleanup_and_exit  "Error: ${gl_cloud_os_version}: unknown ami" 1 ${gl_system_type}
			fi
		fi
		#
		# Check to make sure the architecture matches that of the ami
		#
		if [[ $ami_arch != "" ]]; then
			if [[ $ami_value != *"${ami_arch}"* ]]; then
				cleanup_and_exit  "Error: ami_arch $ami_arch does not match the ami provided: ${ami_value}: wrong arch" 1 ${gl_system_type}
			fi
		fi
	done
}

#
# Verify the cloud os version
#
verify_cloud_os_version()
{
	if [[ "$gl_system_type" == "aws" ]]; then
		show_aws_images $gl_os_vendor 1
	fi
}

#
#   Retrieve the OS versions available for the given cloud vendor and OS vendor
#
cloud_image_lookup()
{
	if [[ "$gl_system_type" == "aws" ]]; then
		show_aws_images $gl_os_vendor 0
	fi

	if [[ "$gl_system_type" == "azure" ]]; then
		#
		# We exit in azure_image_lookup
		#
		azure_image_lookup $gl_os_vendor
	fi

	if [ "$gl_system_type" == "gcp" ]; then
		gcp_image_lookup $gl_os_vendor
	fi
	cleanup_and_exit  "Unknown cloud type $gl_system_type" 1 ${gl_system_type}
}

#
# Pull the version information for the git repository (using tags).
#
retrieve_versions()
{
	file=$1.yml
	if  test -f "$file" ; then
		location=`grep location: ${file} | cut -d: -f2- | sed "s/ //g" | cut -d'/' -f 1-5`
		echo $location
		echo ============================
		echo $1
		echo ============================
		if [[ $location == "https://github.com"* ]]; then
			git -c 'versionsort.suffix=-' ls-remote --exit-code --refs --sort='version:refname' --tags $location
		else
			echo "${location} only github supported at this time"
		fi
	else
		cleanup_and_exit "did not find file ${file}" 1
	fi
}

#
# Show the versions of the given tests.
#
show_test_version()
{
	gl_test_list=`echo $1 | sed "s/,/ /g"`
	make_dir_report_errors tests_to_run
	for test_name in $gl_test_list; do
		cd tests_to_run
		retrieve_versions $test_name
		cd ..
	done
	rm -rf tests_to_run 2> /dev/null
	cleanup_and_exit "" 0
}

#
# Passed a line from a file, return the desired field.
#
# $1: string looking at.
# $2: the field separator
# $3: field pulling
#
grab_a_field()
{
	str_val=`echo $1 | sed "s/\"//g" | sed "s/,$//g"`
	#
	# Check to make sure not going beyond last field.
	# 
	res="${str_val//[^${2}]}"
	len=`echo $res | wc -c`
	if [ $len -lt $3 ]; then
		echo grab_a_field: Field requested is larger then the available fields, $1
		echo Want field ${3}, only have $len fields.
		cleanup_and_exit "" 1
	fi
	ret_field_val=`echo ${str_val} | cut -d$2 -f $3`
	echo "${ret_field_val}"
}

#
# Given a test, try and locate it in the test_info file.  If
# found, simply return, else report the error and exit.
#
verify_test()
{
	test_name=$value_not_set
	looking_for=`echo $1 | sed "s/,/ /g"`
	for i in $looking_for; do
		while IFS= read -r line
		do
			if [[ $line == *"\"test_name\":"* ]]; then
				test_name=$(grab_a_field "${line}" ":" 2)
				test_name=`echo $test_name  | sed "s/ //g"`
				if [[ $test_name == $i ]]; then
					break
				fi
			fi
			test_name=$value_not_set
		done < "test_info"
		if [[ $test_name == $value_not_set ]]; then
			cleanup_and_exit "Unknown test ${i}, exiting out" 1
		fi
	done
}

#
# Pull the available tests and description fields from the test_info file.
#
list_tests_available()
{
	out_file=`mktemp /tmp/zathras_out_file.XXXXX`
	echo "Available tests"
	test_name=""
	test_descript=""
	while IFS= read -r line
	do
		if [[ $line == *"\"test_name\":"* ]]; then
			test_name=$(grab_a_field "${line}" ":" 2)
		fi
		if [[ $line == *"\"test_description\":"* ]]; then
			test_descript=$(grab_a_field "${line}" ":" 2)
			echo "${test_name}: ${test_descript}" >> $out_file
		fi
	done < "test_info"
	sort $out_file
	rm $out_file
	cleanup_and_exit "" 0
}

#
# Look up a yml field in the designated file. Arguments
# 1: file to look at for the field
# 2: level 1 field indicator
# 3: level 1 value looking for
# 4: field looking for.
#
# So from test_info (file created)
# "test_defs": {
#    "test1": {
#      "test_name": "linpack",
#      "test_description": "standard linpack test.",
#      "repository_type": "git_tag",
#      "location": "https://testing",
#      "reboot_system": "none",
#      "test_run_from": "remote",
#
# To pull the test_run_from
# test_run_from=$(find_test_def_field "test_info" "test_name" "linpack" "test_run_from" )
#
find_test_def_field()
{
	field=$4
	file=$1
	grouping=$2
	field_val=$value_not_set
	found=0
	value=""
	fs=""
	test_lookup=`echo $3 | sed "s/,/ /g"`
	for test_check in ${test_lookup}; do
		while IFS= read -r line
		do
			if [[ $found -eq 1 ]]; then
				if [[ $line == *"\"${grouping}\":"* ]]; then
					#
					# Hit the end, bail out.
					#
					break;
				fi
				#
				# Get the field name, and if it is what we are looking for, 
				# process it.
				#
				field_val=$(grab_a_field "${line}" ":" 1)
				if [[ $field_val == $field ]]; then
					field_val=$(grab_a_field "${line}" ":" 2)
					value=${value}${fs}${field_val}
					fs=" "
					break
				fi
				#
				# Have not found the field yet, continue.
				#
				continue;
			fi
			#
			# Check to see if we found the proper grouping. If so set things.
			#
			if [[ $line == *"\"${grouping}\":"* ]]; then
				test_name_ret=$(grab_a_field "${line}" ":" 2)
				test_name=`echo $test_name_ret | sed "s/ /,/g"`
				if [[ $test_name == $test_check ]]; then
					found=1
				fi
			fi
		done <  "${1}"
		if [[ $found -eq 0 ]]; then
			cleanup_and_exit "Error: Did not find the field $field in $test_check aborting." 1
		fi
	done
	echo $value
}

#
# Break out from test_defs.yml the actual test we want to run.  There will be
# a <test>.yml file in tests_to_run for each test we are running.
#
create_test_run_file()
{
	look_for=$1
	found=0

	
	#
	# We want the yaml file, not the converted version.
	while IFS= read -r line
	do
		if [[ $found -eq 1 ]]; then
			#
			# We have found the test, check to see if we are at the end of the test.
			#
			if [[ $line == "" ]]; then
				break;
			fi
			echo $line >> tests_to_run/$1.yml
			continue;
		fi
		if [[ $line == *"test_name:"* ]]; then
			test_name_ret=$(grab_a_field "${line}" ":" 2)
			lcl_test_name=`echo $test_name_ret | sed "s/ //g"`
			if [[ $lcl_test_name == $look_for ]]; then
				rm tests_to_run/$1.yml 2> /dev/null
				echo "---" >> tests_to_run/$1.yml
				echo $line >> tests_to_run/$1.yml
				found=1
			fi
		fi
	done <  "${gl_test_def_dir}/full_test_defs.yml"
}

#
# Determine what packages are needed for the test on this particular flavor linux.
#
obtain_required_packages()
{
	packages=$(find_test_def_field "test_info" "test_name" "$1" "${gl_os_vendor}_pkgs" )
	pbench_usage=$(find_test_def_field "test_info" "test_name" $1 "test_run_from" )
	if [[ "$packages" != $value_not_set ]]; then
		worker=`echo $packages | sed "s/,/ /g"`
		for i in $worker; do
			echo "  - ${i}" >> install_choices
		done
	fi
	#
	# Package install for pbench
	# The packages being installed for pbench need to be reviewed every so often to make sure
	# they are still required
	#
	if [[ $1 == *"pbench"* ]]; then
		echo "  - perf" >> install_choices
	fi
}

#
# Determine the files to upload and make sure they exist.
#
make_list_of_uploads()
{

	test_pulling=$1
	uploads=$(find_test_def_field "test_info" "test_name" "$test_pulling" "upload_extra" )
	upload_files=`echo $uploads | sed "s/,/ /g"`
	for file_to_upload in $upload_files; do
		if [[ ! -f ${file_to_upload} ]] && [[ ${file_to_upload} != "none" ]];  then
			cleanup_and_exit "${file_to_upload}: Can not find" 1
		fi
		echo "  - ${file_to_upload}" >> upload_files.yml
	done
}

make_list_of_rpms_to_upload()
{
	echo "rpm:" >> upload_rpms.yml
	rpm_uploads=`echo $gl_upload_rpms | sed "s/,/ /g"`
	for rpm in $rpm_uploads; do
		if [[ ! -f ${rpm} ]] && [[ ${rpm} != "none" ]];  then
			cleanup_and_exit "${file_to_upload}: Can not find" 1
		fi
		echo "  - ${rpm}" >> upload_rpms.yml
	done
}

#
# Set the repo image type.
#
set_image_type()
{
	found=0
	if [[ $1 == *"iso"* ]]; then
		gl_image_type="iso"
		found=1
	fi
	if [[ $1 == *"ftp"* ]]; then
		gl_image_type="ftp"
		found=1
	fi
	if [ $found -eq 0 ]; then
		cleanup_and_exit "${1}: Unknown image type." 1
	fi
}

#
# General setup 
#
general_setup()
{
	hostdir=`pwd`/ssh_known_hosts
	running_dir=`pwd`
	rm -rf $hostdir 2> /dev/null
	make_dir_report_errors $hostdir
	#
	# Replace test_defs.yml with full_test_defs.yml.
	#
	gl_test_repos=`echo $1 | cut -d' ' -f 2 | sed "s/test_defs.yml/full_test_defs.yml/g"`

	tar cf bin.tar bin
	tar cf tools_bin.tar tools_bin
	tar cf sysctl_settings.tar sysctl_settings
}

#
# To keep us from using the same zone all the time, we randomize it.
# For azure, this is fairly simply as there are only 3 possible zones.
# For aws, it is a bit more complicated, as the number of zones is not the
# same in all regions.
#
obtain_zone()
{
	if [[ $gl_system_type == "aws" ]]; then
		#
		# Retrieve the regions, and figure out how many regions we have.
		#
		aws ec2 describe-availability-zones --region $gl_cloud_region --query "AvailabilityZones[*].{Name:ZoneName}" --output=text > aws_zones
		if [ $? -ne 0 ]; then
			cleanup_and_exit "Unable to retrieve the AWS zones for the region: $gl_cloud_region" 1
		fi
		aws_number_zones=0
		declare -a aws_zones
		for i in `cat aws_zones`
		do 
			aws_zones[${aws_number_zones}]=$i
			let "aws_number_zones=$aws_number_zones+1"
		done
		#
		# Now grab a zone to use.
		#
		index_in=`echo $RANDOM % $aws_number_zones | bc`
		selected=${aws_zones[${index_in}]}
		gl_cloud_region_zone=${selected: -1}
	elif  [[ $gl_system_type == "azure" ]]; then
		#
		# Only have 3 possible zones.
		#
		declare -a azure_zones=("1" "2" "3")
		azure_num_zones=3
		# A default might not be set, pick our own default
		if [[ "$gl_cloud_region" == "" ]]; then
			gl_cloud_region="eastus"
		fi
		index_in=`echo $RANDOM % $azure_num_zones | bc`
		# Note that Azure doesn't always use zones unlike AWS
		# but we'll set it here anyway.
		gl_cloud_region_zone=`echo ${azure_zones[${index_in}]}`
	fi
}

#
# Set cloud defaults
#
set_region_zone_defaults()
{
	if [[ $gl_system_type == "aws" ]]; then
		gl_cloud_region=`aws configure get region`
		if [ $? -eq 1 ]; then
			cleanup_and_exit "Unable to retrieve the AWS region" 1
		fi
		obtain_zone
	elif [[ $gl_system_type == "azure" ]]; then
		gl_cloud_region=`az configure --list-defaults -o tsv | grep location | awk '{print $3}'`
		if [ $? -eq 1 ]; then
			cleanup_and_exit "Unable to retrieve the azure region" 1
		fi
		obtain_zone
	elif [[ $gl_system_type == "gcp" ]]; then
		gl_cloud_region=`gcloud config list compute/region --quiet  | grep region | awk '{ print $3 }'`
		if [ $? -eq 1 ]; then
			cleanup_and_exit "Unable to retrieve the gcp region" 1
		fi
		gl_cloud_region_zone=`gcloud config list compute/zone --quiet | grep zone | awk '{ print $3 }'`
	fi
}


#
# In an effort to keep the known host file list down in size, and to prevent issues in the future when
# we get a recycled cloud name, remove any cloud hostnames that have been added to known hosts.
#
remove_hostnames_added()
{
	if [[ $gl_system_type != "local" ]]; then
		cd $hostdir
		ssh_files_to_remove=`ls remove_from_ssh_* 2> /dev/null`k
		if [ $? -eq 0 ]; then
			for rm_ssh_file in $ssh_files_to_remove;
			do
				for entry in `cat $rm_ssh_file`
				do
					grep -v $entry ~/.ssh/known_hosts > new_known
					mv new_known ~/.ssh/known_hosts
				done
			done
		fi
		cd $gl_top_dir
	fi
}
#
# Fail if any of the following is true.
# The local config is not present
# If the passed string is not present in the local config file.
# If there is no corresponding value to the string passed.
# If there are duplicate values assigned to the string passed.
#
check_for_dup_config_entries()
{
	entries_check=`mktemp /tmp/zathras_dup_check.XXXXX`
	grep "${1}:" ${gl_top_dir}/local_configs/${gl_host_config_info}.config > $entries_check
	if [[ $? -ne 0 ]]; then
		rm $entries_check 2> /dev/null
		cleanup_and_exit "Error: No ${1} entry in ${gl_top_dir}/local_configs/${gl_host_config_info}.config" 1
	fi

	field_option=`awk '{print $2}' $entries_check`
	if [[ $field_option == "" ]]; then
		rm $entries_check 2> /dev/null
		cleanup_and_exit "Error: Field  ${1} is present, but has no entries, ${gl_top_dir}/local_configs/${gl_host_config_info}.config" 1
	fi

	numb_entries=`uniq -c $entries_check | awk '{print $1}'`
	if [[ $numb_entries -gt 1 ]]; then
		rm $entries_check 2> /dev/null
		cleanup_and_exit "Error: Duplicate ${1} entries in ${gl_top_dir}/local_configs/${gl_host_config_info}.config" 1
	fi
	rm $entries_check 2> /dev/null
}

#
# Checks to make sure the following
# 1) If storage is required, storage has been provided, or  type is designated as internal
# 2) If network is required, network has been provided.
# 3) If workload requires java, that java is being installed.
# 4) If workload requires pbench, that pbench is being installed.
#
set_requirements()
{
	pbench_required="no"
	uperf_required="no"
	storage_required="no"
	network_required="no"
	java_required="no"

	gl_install_pbench=0
	worker=`echo $1 | cut -d' ' -f2- | sed "s/,/ /g"`
	for test_name in ${worker};
	do
		#
		# Pbench check.
		#
		if [[ "$pbench_required" == "no" ]]; then
			pbench_required=$(find_test_def_field "test_info" "test_name" "$test_name" "pbench_required" )
			if [[ "$pbench_required" == *"yes"* ]]; then
				#
				# Verify pbench url is defined.
				#
				grep pbench_config_url ${gl_top_dir}/ansible_roles/roles/install_pbench/vars/main.yml > /dev/null
				if [ $? -ne 0 ]; then
					cleanup_and_exit "Asking for pbench, but does not look like pbench urls have been conmfigured." 1
				fi
				gl_install_pbench=1
			fi
		fi
		#
		# Storage check.
		#
		if [[ "$storage_required" == "no" ]] || [ $gl_cloud_number_disks -gt 0 ] ; then
			storage_required=$(find_test_def_field "test_info" "test_name" "$test_name" "storage_required" )
			if [[ "$storage_required" == "yes" ]] || [ $gl_cloud_number_disks -gt 0 ]; then
				if [[ "$gl_system_type" != "local" ]]; then
					if [[ $gl_disks_present == "0" ]]; then
						if [[ "$gl_internal_disks" -eq 0 ]]; then
							cleanup_and_exit "Test ${test_name} requires storage, please resolve configuration issue." 1
						else
							echo Notice: Using internal storage
						fi
					fi
				else
					if [[ "$storage_required" == "yes" ]]; then
						if [[ ! -f ${gl_top_dir}/local_configs/${gl_host_config_info}.config ]]; then
							cleanup_and_exit "Error: local_configs/${gl_host_config_info}.config does not exist.\nRequired for local systems when storage is needed." 1
						fi
						check_for_dup_config_entries storage
					fi
				fi
				disk_check
			fi
		fi
		#
		# Network check.
		#
		if [[ "$network_required" == "no" ]]; then
			network_required=$(find_test_def_field "test_info" "test_name" "$test_name" "network_required" )
			if [[ "$network_required" == "yes" ]]; then
				if [[ "$gl_system_type" != "local" ]]; then
					if [[ $gl_networks_present == "0" ]]; then
						cleanup_and_exit "Test $test_name  requires network, please resolve configuration issue." 1
					fi
				else
					if [[ ! -f ${gl_top_dir}/local_configs/${gl_host_config_info}.config ]]; then
						cleanup_and_exit "Error: local_configs/${gl_host_config_info}.config does not exist.\nRequired for local systems when networks are needed" 1
					fi

					check_for_dup_config_entries server_ips
					check_for_dup_config_entries client_ips
				fi
			fi
		fi
		#
		# Java check
		#
		if [[ "$java_required" == "no" ]]; then
			java_required=$(find_test_def_field "test_info" "test_name" "$test_name" "java_required" )
			if [[ "$java_required" == "yes" ]]; then
				if [[ $gl_java_version == $value_not_set ]]; then
					cleanup_and_exit "Test ${test_name} requires Java, please resolve configuration issue." 1
				fi
			fi
		fi
	done
	echo "  pbench_disk_required: \"${pbench_required}\"" >> ansible_vars_main.yml
	echo "  storage_required: \"${storage_required}\"" >> ansible_vars_main.yml
	echo "  network_required: \"${network_required}\"" >> ansible_vars_main.yml
}

#
# Walk through each test to run and obtain the packages required.
# Before we exit, sort the packages and remove duplicate entries.
#
determine_what_has_to_be_installed()
{
	worker=`echo $1 | cut -d' ' -f2- | sed "s/,/ /g"`

	# Ensure we have a couple packages to install, keeps things nice and happy.
	if [[ $gl_os_vendor == "ubuntu" ]]; then
		echo "  - gzip" > install_choices
	else
		echo "  - bc" > install_choices
		echo "  - numactl" > install_choices
		echo "  - time" >> install_choices
	fi
	echo "---" > upload_files.yml
	echo "uploads:" >> upload_files.yml
	#
	# Walk the list of tests.
	#
	for local_test_name in ${worker};
	do
		obtain_required_packages $local_test_name
		make_list_of_uploads $local_test_name
		#
		# create the *yml file to be used for the test.
		#
		create_test_run_file $local_test_name
	done
	make_list_of_rpms_to_upload
#
#  Now java packages if need be.
#
	if [[ $gl_java_version != $value_not_set ]]; then
		java_package=$(find_test_def_field "${gl_top_dir}/java_info" "java_version" $gl_java_version $gl_os_vendor)
		echo "  - ${java_package}" >> install_choices
	fi

	echo "---" >> install_opts.yml
	echo "pkg_install:" >> install_opts.yml
	sort -u install_choices >> install_opts.yml

}

#
# Parse the system configuration string for the various options.
# They are then set to a the appropriate global value.  As this is done
# for each configuration set, we are able to do this.
#
reduce_options()
{
	option_string=$1
	found=0
	#
	# Obtain disk information
	#
	if [[ $option_string == *"Disk"* ]]; then
		string=$ct_config":"$option_string
		data=`parse_disk_line "${string}"`
		gl_cloud_number_disks=`echo ${data} | cut -d: -f4 | bc`
		gl_cloud_disk_type=`echo ${data} | cut -d: -f3`
		cloud_disk_size=`echo ${data} | cut -d: -f2 | bc`
		cloud_disk_iops=`echo ${data} | cut -d: -f5`
		cloud_disk_tp=`echo ${data} | cut -d: -f6`
		if [[ $gl_cloud_disk_type == "" ]]; then
			cleanup_and_exit "Error: Need to designate the disk type ${data}" 1
		fi
		if [[ $cloud_disk_size -eq 0 ]]; then
			cleanup_and_exit "Error: invalid disk size designated ${data}" 1
		fi
		if [[ $gl_disks_asking_for == "" ]]; then
			gl_disks_asking_for="[\""
		else
			gl_disks_asking_for=${gl_disks_asking_for}","
		fi
		gl_disks_asking_for=${gl_disks_asking_for}${gl_cloud_number_disks}:${gl_cloud_disk_type}:${cloud_disk_size}:${gl_disk_cloud_index}:${cloud_disk_iops}:${cloud_disk_tp}
		let "gl_disk_cloud_index=${gl_disk_cloud_index}+1"
		#
		# indicate if we are using nvme storage.  AWS is always nvme.
		#
		if [[ $gl_system_type == "aws" || ($gl_system_type == "azure" && "$gl_host_config" =~ "^Standard_L[[:digit:]]*_v2*") ]]; then
			gl_host_uses_nvme=1
		else
			gl_host_uses_nvme=0
		fi
		if [[ $cloud_disk_iops != "none" ]]; then
			gl_disk_iops=1
		fi
		if [[ $cloud_disk_tp != "none" ]]; then
			gl_disk_tp=1
		fi
		found=1
	fi
	#
	# Set network information.
	#
	if [[ $option_string == *"Network"* ]]; then
		obtain_network_info $entry
		found=1
	fi

	if [[ $entry == *"CPU_type"* ]]; then
		gl_cpu_type_request=`echo $entry | cut -d'=' -f 2`
		fields=`echo "$entry" | sed "s/&/ /g"`
		for i in $fields; do
			if  [[ $i == *"CPU_type"* ]]; then
				gl_cpu_type_request=`echo $i | cut -d'=' -f 2`
				break
			fi
		done
		found=1
	fi

	if [[ $entry == *"Cloud_Placement"* ]]; then
		gl_cloud_placement=`echo $entry | cut -d'=' -f 2`
		fields=`echo "$entry" | sed "s/&/ /g"`
		for i in $fields; do
			if  [[ $i == *"Cloud_Placement"* ]]; then
				gl_cloud_placement=`echo $i | cut -d'=' -f 2`
				break
			fi
		done
		found=1
	fi

	if [[ $gl_use_spot -eq 1 ]] && [[ $option_string == *"Spot"* ]] && [[ $gl_system_type != "azure" ]]; then
		string=$ct_config":"$option_string
		data=`parse_spot_line "${string}"`
		gl_spot_price=`echo $data| cut -d':' -f 2`
		gl_spot_increment=`echo $data | cut -d':' -f 3`
		gl_spot_cap=`echo $data | cut -d':' -f 4`
		if [[ $gl_spot_cap != "0" ]]; then
			if [[ $gl_spot_increment == "0" ]]; then
				cleanup_and_exit "Error: must designate a spot_increment when spot cap is designated." 1
			fi
		fi
		if [[ $gl_spot_increment != "0" ]]; then
			if [[ $gl_spot_cap == "0" ]]; then
				cleanup_and_exit "Error: must designate a spot_cap when spot increment is designated." 1
			fi
		fi
		found=1
	else
		#
		#  We are ignoring spot pricing, but still have to mark it as found.
		#
		if [[ $option_string == *"Spot"* ]]; then
			found=1
		fi
	fi
	if [[ $option_string == *"Sysctl_setting"* ]]; then
		gl_sys_file=`echo $option_string | cut -d'=' -f 2`
		found=1
	fi
	#
	# Bail if we do not understand the option.
	#
	if [[ $found -eq 0 ]]; then
		cleanup_and_exit  "The option ${option_string} is not a valid config option, aborting." 1
	fi
}

#
# Add in local configuration information, if required.
#
add_local_config_info()
{
	if [[ $gl_system_type == "local" ]]; then
		conf_file="$gl_top_dir/local_configs/${1}.config"
		#
		# If there is a config file, go and retrieve the information.
		#
		if [[ -e $conf_file ]]; then
			conf_file="${gl_top_dir}/local_configs/${1}.config"
			cp $conf_file hw_config.yml
			#
			# Retrieve network connection information.
			#
			server_ips=`grep server_ips $conf_file`
			server_rtc=$?
			if [[ $server_rtc -eq 0 ]]; then
				echo ct_server: `echo $server_ips | cut -d: -f 2`  >> ansible_run_vars.yml
			fi
			client_ips=`grep client_ips $conf_file`
			client_rtc=$?
			if [[ $client_rtc -eq 0 ]]; then
				echo ct_client_ip: `echo $client_ips | cut -d: -f 2` >> ansible_run_vars.yml
			fi
			#
			# Retrieve storage information.
			#
			storage=`grep storage $conf_file`
			if [[ $? -eq 0 ]]; then
				echo storage: `echo $storage | cut -d: -f 2` >> ansible_run_vars.yml
			fi
			if [[ $server_rtc -eq 0 ]]; then
				val=`echo $server_ips | cut -d: -f 2`
				echo "ct_uperf_server_ip: ${val}" >> ansible_run_vars.yml
			fi
			if [[ $client_rtc -eq 0 ]]; then
				val=`echo $client_ips | cut -d: -f 2`
				echo "ct_uperf_client_list: ${val}" >> ansible_run_vars.yml
			fi
			cd ${gl_top_dir}
		else
			echo "ct_uperf_server_ip: none" >> ansible_run_vars.yml
			echo "ct_uperf_client_list: none" >> ansible_run_vars.yml
			echo "storage: none" >> ansible_run_vars.yml
		fi
	else
		#
		# Cloud systems, we use the utility grab_disks.  This utility shows
		# what disks are not in use.  We do not do this for local systems,
		# as disks that are not currently mounted may have information that the 
		# user wants.
		#
		echo "storage: grab_disks" >> ansible_run_vars.yml
	fi
}

#
# Set the cloud region/zone information.
#
set_cloud_region()
{
	if [[ $1 == "" ]]; then
		return;
	fi
	if [[ $1 == *"region"* ]]; then
		gl_cloud_region=`echo $1 | cut -d'=' -f 2`
	fi
	if [[ $1 == *"zone"* ]]; then
		gl_cloud_region_zone=`echo $1 | cut -d'=' -f 2`
	fi
}

#
# test user set up.
# This varies from system to system.
# aws will either be ubuntu or ec2-user
# azure is the user name of who is running burden
# local (direct ip/hostname) is root.
#
set_user_name()
{
	if [[ $gl_test_user == "" ]]; then
		if [[ $gl_system_type == "aws" ]]; then
			if [[ $gl_os_vendor == "ubuntu" ]]; then
				gl_test_user=ubuntu
			else
				gl_test_user=ec2-user
			fi
		elif [[ $gl_system_type == "azure" ]]; then
			# Azure normally defaults to the running username
			gl_test_user=${user_name}
		elif [[ $gl_system_type == "gcp" ]]; then
			gl_test_user=${user_name}
		else
			#
			# Default to root
			#
			gl_test_user=root
		fi
	fi
	echo "  test_user: $gl_test_user" >> ansible_vars_main.yml
}

#
# Way things are set up for Azure, we are forced to have some specific knowledge within
# burden.
#
azure_specific_os_version()
{
	run_dir_updated=`echo $run_dir | sed "s/Standard_//g"`
	user_name_len=`echo ${user_name} | wc -c`
	#
	# Allow room for iteration attempt and instance number
	#
	number_chars=`echo "57-${user_name_len}" | bc`
	az_postfix=`echo ${run_dir_updated} | sed "s/\//-/g" | sed "s/_/-/g" | sed "s/,/-/g" | rev| cut -c1-${number_chars} | rev | sed "s/^-//g"`
	az_cloud_resource_group=${user_name}-${az_postfix}
	echo "  cloud_resource_group: ${az_cloud_resource_group}-00" >> ansible_vars_main.yml
	#
	# Azure wants to be difficult about this ... fine.
	# This is gross, fix it to be pretty some day
	#
	azpublisher=`az vm image show --location eastus --urn ${gl_cloud_os_version} | grep publisher | cut -d: -f 2 | cut -d'"' -f 2`
	azoffer=$(echo $gl_cloud_os_version | cut -f 2 -d:)
	azsku=$(echo $gl_cloud_os_version | cut -f 3 -d:)
	azversion=$(echo $gl_cloud_os_version | cut -f 4 -d:)
	echo "  cloud_offer: ${azoffer}" >> ansible_vars_main.yml
	echo "  cloud_publisher: ${azpublisher}" >> ansible_vars_main.yml
	echo "  cloud_os_version: ${azversion}" >> ansible_vars_main.yml
	#
	# Because the sku may contain an _, and ansible when it replaces the 
	# variables in the tfvars.j2 file later will unquote _.
	# After the envars file  is created, we remove the '_' to be _.
	#
	sku=`echo $azsku | sed "s/_/'_'/g"`
	echo "  cloud_sku: ${sku}" >> ansible_vars_main.yml
}

aws_specific_os_version()
{
	vmtype=`echo $1 | cut -d':' -f 1`
	ami_found=0

	#
	# vmtype has been verified, do not have to worry about failure of the command here.
	#
	architecture=`aws ec2 describe-instance-types --instance-type ${vmtype} | grep SUPPORTEDARCHITECTURES | awk '{print $2}'`
	work_with=`echo $gl_cloud_os_version | sed "s/,/ /g"`

	for ami in $work_with; do
		if [[ $ami == *":"* ]]; then
			ami_check=`echo $ami | cut -d':' -f2`
		else
			ami_check=$ami
		fi
		ami_value=`aws ec2 describe-images --query 'sort_by(Images, &CreationDate)[*].[CreationDate,Name,ImageId]' --filters "$filter" --output table | egrep "${start_date}|${end_date}" | grep "${ami_check}"`
		if [[ $ami_value == "" ]]; then
			get_cloud_acct_id
			ami_value=`aws ec2 describe-images --owners $gl_cloud_acct_id | grep IMAGES | grep $ami_check`
		fi
		if [[ $ami_value == *"${architecture}"* ]]; then
			echo "  cloud_os_version: ${ami_check}" >> ansible_vars_main.yml
			ami_found=1
			break
		else
			#
			# Because AWS ubuntu shows up as AMD
			#
			if [[ ${architecture} == "x86_64" ]]; then
				if [[ $ami_value == *"amd64"* ]]; then
					echo "  cloud_os_version: ${ami_check}" >> ansible_vars_main.yml
					ami_found=1
					break
				fi
			fi
		fi
	done
	if [[ $ami_found -eq 0 ]]; then
		cleanup_and_exit "Error: no ami in the list ${gl_cloud_os_version} that matches the architecture $architecture" 1
	fi
}

#
# If spot variables have not been set, then set from the config/spot_price.cfg file.
#
retrieve_spot_from_config()
{
	if [[ $gl_use_spot -eq 1 ]]; then
		if [[ $gl_system_type == "aws" ]]; then
			#
			# For AWS obtain the possible starting price.
			#
			worker=`aws ec2 describe-spot-price-history --start-time=$(date +%s) --product-descriptions="Linux/UNIX" --query 'SpotPriceHistory[*].{az:AvailabilityZone, price:SpotPrice}' --instance-types $host_or_cloud_inst | tail -1 | awk '{ print $2 }'`
			if [[ $? -ne 0 ]]; then
				cleanup_and_exit "Error: unable to retrieve spot info for $1" 1
			fi
			gl_spot_price=$worker
			gl_spot_cap=$gl_base_cost
			#
			# We will default to 5 intervals
			# 
			gl_spot_increment=`echo "scale=2;((($gl_spot_cap - $gl_spot_price)*1.5)/5.00)" | bc`

		elif [[ $gl_system_type == "gcp" ]]; then
		  echo "spot prices not to be provided in case of gcp."
		else
			if [[ $gl_system_type != "azure" ]]; then
				spot_string=`grep $1 ${gl_test_def_dir}/spot_price.cfg`
				if [[ $? -ne 0 ]]; then
					cleanup_and_exit "Error: no spot information present for $1" 1
				fi
				gl_spot_price=`echo ${spot_string} | cut -d':' -f2`
				gl_spot_increment=`echo ${spot_string} | cut -d':' -f3`
				gl_spot_cap=`echo ${spot_string} | cut -d':' -f4`
			fi

		fi
	fi
}

#
# Check to make sure we have not exceeded the maximum # disks.
#
disk_check()
{
	if [[ $gl_system_type == "aws" ]]; then
		if [[ $gl_cloud_disk_type != "internal" ]]; then
			if [[ $gl_cloud_number_disks -eq 0 ]]; then
				cleanup_and_exit "Error: Disks where designated, but the number of disks being used is 0." 1
			fi
			if [[ $gl_install_pbench -eq 1 ]]; then
				if [[ $gl_cloud_number_disks -gt 9 ]]; then
					cleanup_and_exit "Error: AWS Maximum # disks when pbench is present is 9, you designated $gl_cloud_number_disks" 1
				fi
			else
				if [[ $gl_cloud_number_disks -gt 10 ]]; then
					cleanup_and_exit "Error: AWS Maximum # disks is 10, you designated $gl_cloud_number_disks" 1
				fi
			fi
		fi
	fi
}

#
# We use the tags.conf file to generate the various desired tags.  If the
# file is not present, we will use a set of defaults.
#
generate_tags()
{
	if [[ -f ${gl_test_def_dir}/tags.conf ]]; then
		#
		# First generate the set of information
		#
		cat ${gl_test_def_dir}/tags.conf  | sed "s/Your name/${1}/g" | sed "s/PROJECT/${gl_run_prefix}_${gl_os_vendor}/g" >> tags_defaults
	else
		#
		# Default tags.
		#
		echo "  Jirald: ${1}" >> tags_defaults
  		echo "  User: ${1}" >> tags_defaults
  		echo "  Owner: ${1}" >> tags_defaults
  		echo "  Manager: Unknown" >> tags_defaults
  		echo "  Project: Testing" >> tags_defaults
  		echo "  Environment: Test" >> tags_defaults
  		echo "  Jirald: ${1}" >> tags_defaults
	fi
	#
	# Ok now add the variable information into the various files
	# This sets them up to be set  when the system is created or
	# shortly after it is created via terraform.  The various
	# cloud subsections will update the required files.
	#
	cat tags_defaults >> ansible_vars_main.yml
	if [[ $gl_system_type == "aws" ]]; then
		echo "provider \"${gl_system_type}\" {" >> add_main_vars.tf
  		echo "  profile = \"default\"" >> add_main_vars.tf
  		echo "  region  = var.region" >> add_main_vars.tf
  		echo "  default_tags {" >> add_main_vars.tf
		echo "    tags = {" >> add_main_vars.tf
		indent="      "
	fi
	if [[ $gl_system_type == "azure" ]]; then
		echo "locals {" >> add_main_vars.tf
		echo "  tags = {" >> add_main_vars.tf
		indent="        "
	fi
	if [[ $gl_system_type == "gcp" ]]; then
	  echo "provider \"google\" {" >> add_main_vars.tf
	  echo "  project     = \"${1}\"" >> add_main_vars.tf
	  echo "  default_tags {" >> add_main_vars.tf
	  echo "    tags = {" >> add_main_vars.tf
	  indent="        "
	fi

	#
	# Generic addition of information.
	#
	aws_tags=""
	tag_separ=""
	while IFS= read -r line
	do
		value=`echo $line  | cut -d':' -f 1 | sed "s/ //g"`
		echo "variable \"${value}\" {" >> add_vars_tf
  		echo "  type = string" >> add_vars_tf
  		echo "  default = \"none\"" >> add_vars_tf
		echo "}" >> add_vars_tf
		echo "${value} = \"{{ config_info.${value} }}\"" >> add_main_tf_vars
		echo "${indent}${value} = \"\${var.${value}}\"" >> add_main_vars.tf
		#
		# Terraform spot does not set the tags, build a tag list (AWS only)
		#
		if [ $gl_use_spot -eq 1 ] && [[ $gl_system_type == "aws" ]]; then
			tag_value=`echo $line  | cut -d':' -f 2 | sed "s/ //g"`
			aws_tags="${aws_tags}${tag_separ}Key=${value},Value=${tag_value}"
			tag_separ=" "
		fi
	done < "tags_defaults"
	if [[ $aws_tags != "" ]]; then
		aws_tags="${aws_tags}${tag_separ}Key=Name,Value=${1}_${gl_run_prefix}_${gl_os_vendor}"
		echo $aws_tags >> aws_set_tags
	fi
	#
	# Done, now end it.
	#
	if [[ $gl_system_type == "aws" ]]; then
		echo "    }" >> add_main_vars.tf
		echo "  }" >> add_main_vars.tf
	fi
	if [[ $gl_system_type == "azure" ]]; then
		echo "    }" >> add_main_vars.tf
	fi
	if [[ $gl_system_type == "gcp" ]]; then
		echo "    }" >> add_main_vars.tf
		echo "  }" >> add_main_vars.tf
	fi
	echo "}" >> add_main_vars.tf
}
#
#  Using all the options entered, create the working directory for the configuration and it's
#  associated files.
#
create_ansible_options()
{
	dir_list=""
	declare -a pids
	index=1
	pindex=0

	#
	# Parse the test list and make sure they all exist
	#
	worker=`echo $gl_test_list_out | cut -d' ' -f2- | sed "s/,/ /g"`
	for test_name in ${worker};
	do
		verify_test $test_name
	done

	#
	#
	# We do this for each host, at this point we have everything in the
	# required formats.
	#
	for create_host in $config
	do
		gl_spot_price=0
		gl_spot_cap="0"
		gl_spot_increment="0"
		#
		# Set any cloud regions/zones
		#
		set_region_zone_defaults

		ct_config=`echo ${create_host} | cut -d: -f1 | cut -d'[' -f 1`
		#
		# Do we need to parse the config options, ie region, zone???
		#
		if [[ $create_host == *"["* ]]; then
			gl_cloud_region_zone=""
			gl_cloud_region=""
			worker=`echo $create_host | cut -d'[' -f 2 |cut -d']' -f 1`
			#
			# Right now just region and zone, either one may be here.
			#
			if [[ $worker == *"&"* ]]; then
				# We have both fields
				worker1=`echo $worker | cut -d'&' -f 1`
				worker2=`echo $worker | cut -d'&' -f 2`
			else
				worker1=$worker
				worker2=""
			fi
			set_cloud_region $worker1
			set_cloud_region $worker2
			if [[ -z $gl_cloud_region_zone ]]; then
				obtain_zone
			elif [[ $gl_system_type == "gcp" ]]; then
				#TODO: Default else doesn't work for gcp and shouldn't be set anyways
				gl_cloud_region=${gl_cloud_region}
			else
				gl_cloud_region=${gl_cloud_region}${gl_cloud_region_zone}
			fi
		fi
		#
		# Process the various options.
		#
		if [[ $create_host == *":"* ]]; then
			field_index=2
			field_1=`echo $create_host | cut -d':' -f $field_index`

			if [[ $field_1 == *"&"* ]]; then
				index_in=1
				field_op=`echo $field_1 | cut -s -d'&' -f $index_in` 2> /dev/null
				while [[ $field_op != "" ]]
				do
					reduce_options $field_op
					let "index_in=${index_in}+1"
					field_op=`echo $field_1 | cut -s -d'&' -f $index_in` 2> /dev/null
				done
			else
				if [[ $field_1 != "" ]]; then
					reduce_options $field_1
				fi
			fi
		fi
		if [[ $gl_disks_asking_for != "" ]]; then
			gl_disks_asking_for=${gl_disks_asking_for}\""]"
		fi
		#
		# We have the host options now (Disks, Networks, and Sysctl)
		#
		# Generate the host information and run_dir
		#
		host_or_cloud_inst=$ct_config
		gl_host_config_info=`echo ${create_host} | sed s/';'/_/g | sed s/'\['/_/g | sed s/'\]'/_/g`

		#
		# If we did not find spot pricing, check the config/spot_price for the instance type,
		# and populate if required.
		#
		if [[ $gl_system_type != "local" ]] && [[ $gl_spot_cap -eq 0 ]]; then
			echo No spot price designated, retrieving
			worker=`curl -L ec2.shop?filter=$1 -H 'accept: json'`
			if [[ $? -ne 0 ]]; then
				cleanup_and_exit "Unable to retrieve base cost $1" 1
			fi
			if [[ $gl_system_type == "aws" ]]; then
				worker=`curl -L ec2.shop?filter=$host_or_cloud_inst -H 'accept: json'`
				gl_base_cost=`echo $worker | cut -d':' -f 8 | cut -d',' -f 1`
			fi
			retrieve_spot_from_config $host_or_cloud_inst
		fi

		#
		# Build the run directory
		#
		test_index=0;
		#
		# Azure, we have a limit on resource group name, need the test_index.
		#
		if [[ $gl_sys_type == "azure" ]]; then
			run_dir=${gl_run_prefix}/${gl_os_vendor}/${gl_system_type}/${test_index}_${host_or_cloud_inst}
		else
			run_dir=${gl_run_prefix}/${gl_os_vendor}/${gl_system_type}/${host_or_cloud_inst}_${test_index}
		fi
		#
		# Create the working directory and cd to it.  Without this, we will only be able
		# to run one test at a time.
		#
		/usr/bin/stat $run_dir > /dev/null 2>&1
		rc=$?
		while [ $rc -eq 0 ]
		do
			let "test_index=$test_index+1"
			if [[ $gl_sys_type == "azure" ]]; then
				run_dir=${gl_run_prefix}/${gl_os_vendor}/${gl_system_type}/${test_index}_${host_or_cloud_inst}
			else
				run_dir=${gl_run_prefix}/${gl_os_vendor}/${gl_system_type}/${host_or_cloud_inst}_${test_index}
			fi
			stat $run_dir > /dev/null 2>&1
			rc=$?
		done

		echo ${gl_run_prefix}/${gl_os_vendor}/${gl_system_type} >> ${gl_top_dir}/run_info
		make_dir_report_errors $run_dir
		dir_list=$dir_list$run_dir" "
		cp ${gl_test_def_dir}/test_defs.yml $run_dir
		cp ${gl_test_def_dir}/full_test_defs.yml $run_dir
		if [[ $gl_run_file != "" ]]; then
			cp $gl_run_file $run_dir
		fi
		cp test_info $run_dir
		cp utils_version $run_dir
		pushd $run_dir > /dev/null
		if [ $gl_use_spot -eq 0 ]; then
			echo $gl_base_cost >> instance_cost
		else
			if [[ $gl_system_type == "aws" ]]; then
				echo $gl_base_cost > if_spot_fail
			fi
			echo 0 >> instance_cost
		fi
		make_dir_report_errors tf
		make_dir_report_errors tests_to_run
		make_dir_report_errors tests_to_use
		#
		# Create file that can be ignored. Needed so we can look for files.
		#
		echo "---" > ignore.yml
		echo "ignore:" >> ignore.yml
		echo "  ignore: 0" >> ignore.yml
		#
		# determine_what_has_to_be_installed
		#
		determine_what_has_to_be_installed "$gl_test_list_out"
		#
		# Record the test options for future use by ansible.
		#
		echo --- > ansible_vars_main.yml
		echo config_info: >> ansible_vars_main.yml
		echo "  "hostname_file: $hostdir >> ansible_vars_main.yml
		echo "  "local_run_dir: $running_dir >> ansible_vars_main.yml
		verify_system_type $gl_system_type
		echo "  "system_type: $gl_system_type >> ansible_vars_main.yml
		system_name=`echo $create_host | cut -d':' -f1`
		export_host_config_info=`echo "${system_name}" | sed "s/&/-/g"`
		echo "  "host_config: $system_name >> ansible_vars_main.yml
		echo "  "host_config_info: $export_host_config_info >> ansible_vars_main.yml
		echo "  "host_or_cloud_inst: $host_or_cloud_inst >> ansible_vars_main.yml
		echo "  "cpu_type_request: $gl_cpu_type_request >> ansible_vars_main.yml
		if [ $gl_use_spot -eq 0 ]; then
		  echo "  "vm_type: "regular" >> ansible_vars_main.yml
		else
		  echo "  "vm_type: "preemptible" >> ansible_vars_main.yml
		fi
		if [[ $gl_cloud_placement != "none" ]]; then
			#
			# Azure, only proximity setting at this time, so it can be whatever the user wants.
			#
			if [[ $gl_system_type == "aws" ]]; then
				if [[ $gl_cloud_placement != "cluster" ]] && [[ $gl_cloud_placement != "partition" ]] && [[ $gl_cloud_placement != "spread" ]]; then
					cleanup_and_exit "Unknown AWS placement group ${gl_cloud_placement}." 1
				fi
			elif [[ $gl_system_type == "gcp"  ]]; then
				cleanup_and_exit "We do support GCP placement groups at this time." 1
			fi
		fi
		echo "  "cloud_placement: $gl_cloud_placement >> ansible_vars_main.yml
		echo "  "run_label: ${gl_run_prefix}_${gl_os_vendor} >> ansible_vars_main.yml
		echo "  "do_not_install_packages: ${gl_no_packages} >> ansible_vars_main.yml
		echo "  "error_repo_errors: ${gl_error_repo_errors} >> ansible_vars_main.yml
		spot_pricing=0
		if [[ $gl_spot_price != "0" ]]; then
			#
			# Bash does not do floating point, must use bc
			#
			spot_pricing="["
			spot_separ=""
			cap=`echo ${gl_spot_cap}*100 | bc | cut -d'.' -f1`
			spot_start=`echo ${gl_spot_price}*100 | bc | cut -d'.' -f1`
			if [[ $gl_spot_increment != "0" ]]; then
				increment_by=`echo ${gl_spot_increment}*100 | bc | cut -d'.' -f1`
			else
				increment_by=$cap
			fi

			spot_cur_price=`echo "${spot_start}+${increment_by}" | bc | cut -d'.' -f1`
			while [[ ${spot_cur_price} -le ${cap} ]]; do
				price_out=`printf '%4.2f\n' $(bc -l<<<${spot_cur_price}/100)`
				spot_pricing="${spot_pricing}${spot_separ}${price_out}"
				let "spot_cur_price=$spot_cur_price+$increment_by"
				spot_separ=','
			done
			spot_pricing="${spot_pricing}${spot_separ}${gl_spot_cap}]"
		else
			spot_start=0
		fi
		if [[ $gl_system_type == "azure" ]] && [[ gl_use_spot -eq 1 ]]; then
			gl_spot_price=1
		fi
		echo "  spot_start_price: ${gl_spot_price}" >> ansible_vars_main.yml
		echo "  spot_range: ${spot_pricing}" >> ansible_vars_main.yml
		echo "  "selinux_state: $gl_selinux_state >> ansible_vars_main.yml
		echo "  "selinux_level: $gl_selinux_level >> ansible_vars_main.yml
		user_name=`id | cut -d'(' -f 2 | cut -d')' -f 1`
		#
		# Verify the cloud os version is valid
		verify_cloud_os_version
		#
		# We are forced to have some azure specific information.
		#
		if [[ $gl_system_type = "azure" ]]; then
			azure_specific_os_version
		elif [[ $gl_system_type = "aws" ]]; then
			aws_specific_os_version $system_name
		else
			echo "  cloud_os_version: ${gl_cloud_os_version}" >> ansible_vars_main.yml
		fi
		echo "  test_repos: ${gl_test_repos}" >> ansible_vars_main.yml
		echo "  force_upload: ${gl_cloud_force_upload}" >> ansible_vars_main.yml
		echo "  cloud_terminate_instance: ${gl_cloud_terminate_instance}" >> ansible_vars_main.yml
		echo "  update_os_version: ${gl_update_target}" >> ansible_vars_main.yml
		echo "  update_type: ${gl_image_type}" >> ansible_vars_main.yml
		echo "  persistent_log: ${gl_persistent_log}" >> ansible_vars_main.yml
		echo "  kit_upload_directory: ${gl_kit_upload_directory}" >> ansible_vars_main.yml
		if [[ $gl_ssh_key_file == "" ]]; then
			echo "  ssh_key: $HOME/.ssh/id_rsa" >> ansible_vars_main.yml
		else
			echo "  ssh_key: ${gl_ssh_key_file}" >> ansible_vars_main.yml
		fi
		#
		# local system type, user is expected to be root. cloud systems are expected
		# to be non-root.
		#
		if [[ $gl_system_type == "local" ]]; then
			echo "  user_parent_home_dir: /" >> ansible_vars_main.yml
		else
			echo "  user_parent_home_dir: /home" >> ansible_vars_main.yml
		fi

		echo "  java_version: ${gl_java_version}" >> ansible_vars_main.yml
		if [[ ${gl_rhel_tuned_setting} == "none" ]]; then
			echo "  rhel_tuned_setting: ${gl_rhel_tuned_setting}" >> ansible_vars_main.yml
		else
			echo "  rhel_tuned_setting: [${gl_rhel_tuned_setting}]" >> ansible_vars_main.yml
		fi
		echo "  rhel_tuned_reboot: ${gl_rhel_tuned_reboot}" >> ansible_vars_main.yml
		echo "  cloud_execute_tests: ${gl_cloud_execute_tests}" >> ansible_vars_main.yml
		verify_os_vendor $gl_os_vendor
		echo "  os_vendor: ${gl_os_vendor}" >> ansible_vars_main.yml
		ans_test=`echo ${gl_test_list_out} | cut -d' ' -f 2-`
		#
		# If we are only creating the cloud image, there will be no tests.
		#
		if [[ $ans_test != "" ]]; then
			test_exec_location=$(find_test_def_field "test_info" "test_name" "$ans_test" "test_run_from" )
			if [[ $test_exec_location == *"Error:"* ]]; then
				cleanup_and_exit "Unable to find test_location ${ans_test}" 1
			fi
			echo "  "test_to_run: "["$ans_test"]" >> ansible_vars_main.yml
			echo "  "test_exec_location: $test_exec_location  >> ansible_vars_main.yml
		else
			echo "  test_to_run: [\"0\"]" >> ansible_vars_main.yml
			echo "  test_exec_location: none"  >> ansible_vars_main.yml
		fi

		#
		# More differences in the cloud space that has to be addressed here.
		#
		if [[ $gl_system_type == "aws" ]]; then
			echo "  cloud_region: ${gl_cloud_region}${gl_cloud_region_zone}" >> ansible_vars_main.yml
		elif [[ $gl_system_type == "azure" ]]; then
			# Azure does not put the zone in the region name
			echo "  cloud_region: ${gl_cloud_region}" >> ansible_vars_main.yml
		elif [ $gl_system_type == "gcp" ]; then
			echo "  cloud_region: ${gl_cloud_region}" >> ansible_vars_main.yml
			echo "  cloud_zone: ${gl_cloud_region_zone}" >> ansible_vars_main.yml
		fi
		#
		# Record items that we need to do.
		#
		set_requirements "$gl_test_list_out"

		echo "  cloud_delete_region: ${gl_cloud_region}" >> ansible_vars_main.yml
		if [[ $gl_disks_asking_for == "" ]] || [[ $gl_disks_asking_for == *"internal"* ]] ; then
			#
			# Need a value here to keep AWS terraform happy.
			#
			if [[ $gl_system_type == "aws" ]]; then
				echo "  cloud_disks: [\"0:na:na:0\"]" >> ansible_vars_main.yml
			elif [[ $gl_system_type == "gcp" ]]; then
			  echo "  cloud_disks: []" >> ansible_vars_main.yml
			else
				echo "  cloud_disks: none" >> ansible_vars_main.yml
			fi
		else
			echo "  cloud_disks: ${gl_disks_asking_for}" >> ansible_vars_main.yml
		fi
		gl_disk_cloud_index=0
		echo "  disk_iops: ${gl_disk_iops}" >> ansible_vars_main.yml
		echo "  disk_tp: ${gl_disk_tp}" >> ansible_vars_main.yml
		echo "  host_uses_nvme: ${gl_host_uses_nvme}" >> ansible_vars_main.yml
		echo "  cloud_numb_networks: ${gl_networks_present}" >> ansible_vars_main.yml
		if [[ ${gl_cloud_networks_sys} == *"number=1"* ]]; then
			echo "  cloud_network_systems: none" >> ansible_vars_main.yml
		else
			echo "  cloud_network_systems: ${gl_cloud_networks_sys}" >> ansible_vars_main.yml
		fi
		echo "  cloud_numb_network_type: ${gl_cloud_net_type}" >> ansible_vars_main.yml
		echo "  test_iterations: ${gl_test_iterations}" >> ansible_vars_main.yml
		echo "  user_running: ${user_name}" >> ansible_vars_main.yml
		set_user_name $user_name
		generate_tags $user_name
		#
		# Installation options
		#
		if [ $gl_no_pbench_install -eq 0 ]; then
			echo "  pbench_install: ${gl_install_pbench}" >> ansible_vars_main.yml
		else
			if [ $gl_install_pbench -eq 1 ]; then
				echo "Notice: Benchmark requires pbench, you designated not to install pbench"
			fi
			echo "  pbench_install: 0" >> ansible_vars_main.yml
		fi
		echo "  pbench_tool_level: ${gl_pbench_stats}" >> ansible_vars_main.yml
		if [[ $gl_install_pbench -eq 1 ]]; then
			if [[ "$gl_os_vendor" != "rhel" ]]; then
				cleanup_and_exit "Pbench is only usable with RHEL at this time." 1
			fi
		fi

		#
		# Handle local config info in ansible_run_vars.yml, networks, disks.  Hostname is added via
		# ansible
		#
		add_local_config_info $ct_config
		cd $gl_top_dir
		#
		# Reset everything for the next round. 
		#
		gl_disks_asking_for=""
		#
		# Start the test in the background, record the pid and bump the index.
		#
		if [[ $gl_no_clean_up -eq 0 ]] && [ $gl_cloud_terminate_instance -eq 1 ]; then
			rm_tf_dirs="-r"
		else 
			rm_tf_dirs=""
		fi
		#
		# Update repos to use if required.
		# Simple process
		# 1) Check to see if the new repo package name exist in the template file.
		#    If not, simply give a warning.
		# 2) Obtain the base repo package name, expected format is <os vendor>_pkg_<vers>
		# 3) Rename <os_vendor>_pkgs: to be <os_vendor>_pkgs_orig:
		# 4) Rename the package told to use to be <os_vendor>_pkgs:
		#
		# If a new package name is added in, do not forget to add it to config/entry_order
		#
		if [[ $gl_package_name != $value_not_set ]]; then
			pushd $run_dir/tests_to_run > /dev/null
			orig_package=`echo $gl_package_name | cut  -d'_' -f1,2`
			for i in `ls`; do
				grep "^${gl_package_name}:" $i > /dev/null
				if [[ $? -eq 0 ]]; then
					sed "s/^${orig_package}:/${orig_package}_orig:/g" $i > temp
					sed "s/^${gl_package_name}:/${orig_package}:/g" temp > $i
					rm temp
				else
					echo Warning: $i does not contain $gl_package_name
					echo If it is present, then check config/entry_order to make
					echo sure the entry is in that file also.
				fi
			done
			popd > /dev/null
		fi
		if [ $gl_preflight -eq 0 ]; then
			base_string="-t $gl_top_dir -d $run_dir -f $gl_sys_file -a $gl_create_attempts -S $gl_spot_recover -c $gl_test_def_dir $rm_tf_dirs "
			if [[ "$gl_ssh_key_file" != "" ]]; then
				base_string="${base_string} -s $gl_ssh_key_file"
			fi
			echo $cli "${arguments[@]}" | sed "s/bin/./g" > ${run_dir}/exec_command
			kick_off.sh $base_string | tee ${run_dir}/ansible_log &
			pids[${pindex}]=$!
			let "pindex=$pindex+1"
			if [[ $pindex -eq $gl_max_systems ]]; then
				for pid in ${pids[*]}; do
					wait $pid
				done
				pindex=0
			fi
		fi
	done
	if [ $gl_preflight -ne 0 ]; then
		echo Preflight complete
		exit 0
	fi

	#
	# Wait for everyone to finish up.
	#
	for pid in ${pids[*]}; do
		wait $pid
	done

	#
	# Archive data if requested to do so.
	#
	if [[ $gl_archive_location != $value_not_set ]]; then
		make_dir_report_errors $gl_archive_location
	fi
	timestamp=`date`
	for direct in $dir_list; do
		if [[ $gl_archive_location != $value_not_set ]]; then
			make_dir_report_errors $gl_archive_location/$direct
			pushd $direct > /dev/null
			cp -R * $gl_archive_location/$direct
		else
			pushd $direct > /dev/null
		fi
		worker=`echo $gl_test_list_out | cut -d' ' -f2- | sed "s/,/ /g"`
		if [ -d "tests_to_run" ]; then
			echo "========================================" > results_info
			if [[ $gl_sys_type != "local" ]]; then
				test_sys=`grep host_or_cloud_ins ansible_vars.yml | cut -d':' -f 2 | sed "s/ //g"`
			else
				test_sys=${gl_host_config}
			fi
			echo "system config: ${test_sys}" >> results_info
			for i in `ls tests_to_run`
			do
				pbench_usage=`grep pbench_required: tests_to_run/$i`
				test_location=`grep location: tests_to_run/$i`
				test_specific=`grep test_specific: tests_to_run/$i`
				test_script_to_run=`grep test_script_to_run: tests_to_run/$i`
				test=`echo $i | cut -d'.' -f 1`
				results_file=`ls -d results_${test}*`
				echo "  test: ${test}" >> results_info
				echo "    date: ${timestamp}" >> results_info
				if [[ -f "hw_config.yml" ]]; then
					while IFS= read -r line
					do
						echo "   ${line}" >> results_info
					done < "hw_config.yml"
				fi
				echo "    ${test_location}" >> results_info
				echo "    ${test_script_to_run}" >> results_info
				echo "    ${test_specific}" >> results_info
				timestamp=`date`
				if [[ ${results_file} == "" ]]; then
					timestamp=`date`
					flock -x $gl_top_dir/failed_runs echo "${timestamp} ${test_sys}, Error: $i did not produce a results file" >> $gl_top_dir/failed_runs
					echo "    Error: did not produce a results file" >> results_info
				else
					make_dir_report_errors junk
					cd junk
					for i in $results_file; do
						unzip -q ../${i}
						tfile=`ls *tar`
						results_report=`tar xvf ${tfile} | grep test_results_report`
						if [[ $results_report != "" ]]; then
							grep -q Failed $results_report
							if [ $? -ne 1 ]; then
								echo "${timestamp} Error: System: ${test_sys}, Test, $i, reported failure" >> $gl_top_dir/failed_runs
								echo "    Error: reported a failure" >> ../results_info
							fi
						fi
						rm $tfile
					done
					cd ..
					rm -rf junk
					echo "    results_ptr: ${direct}/${results_file}" >> results_info
				fi
			done
			flock -x $gl_top_dir/results_info cat results_info >> $gl_top_dir/results_info
		fi
		if [[ $gl_archive_location != $value_not_set ]]; then
			cp results_info $gl_archive_location/$direct/$direct_${results}
			#
			# We do not want ssh perm files there.
			#
			rm -rf $gl_archive_location/$direct/config 2> /dev/null
		fi
		rm -rf results_info tests*
		popd > /dev/null
	done
}

#
# If required, retrieve the iso update.
# Only the first process will download the iso, this is controlled by the
# lock_file.
#
update_the_image()
{
	target_image=$1
	set_image_type $target_image
	echo "obtaining update images."

	if [[ $gl_update_target == *"iso"* ]]; then
		which wget  2> /dev/null
		if [[ $? -eq 1 ]]; then
			cleanup_and_exit "wget is not installed, please install, can not retrieve the iso images." 1
		fi
		tools_bin/update_system --update_target $target_image --requestor $BASHPID --update_type $image_type
		if [ $? -ne 0 ]; then
			cleanup_and_exit "Update of image has failed."
		fi
	fi

	echo "Done with obtaining image"
}

#
# We could put this on each line in the appropriate function, but if 
# in the future we decide to change the output of this, we only have to
# do it in one place.
#
report_util_version()
{
	echo ${1}: ${2} >> utils_version
}

#
# Package checking operations. For each required package, we have a function that will check for 
# the package, and report any issues.
#
check_for_yq()
{
	which yq 2> /dev/null
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "yq needs to be installed, to use the --test_def, please install." 1
	fi 
	#
	#  yq spits version out to stderr.
	#
	yq_version=$(yq --version 2>&1)
	echo "Running with yq version ${yq_version}, tested with 2.10.0"
	report_util_version yq_version "${yq_version}"
}

check_for_jq()
{
	which jq 2> /dev/null
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "jq needs to be installed, to use the --test_def, please install.\nyum install jq\n"
	fi 
	jq_version=`jq --version`
	report_util_version jq_version "${jq_version}"
}

check_for_ansible()
{
	which ansible 2> /dev/null
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "Ansible is not installed, please install.\ndnf install -y ansible" 1
	fi 
	ansible_version=`ansible --version | grep ^ansible | awk '{print $2}'`
	echo "Running with ansible version: ${ansible_version}"
	echo "Zathras developed using ansible version:  2.9.6"
	ansible_full_version=`ansible --version`
	report_util_version ansible_version "${ansible_full_version}"
}

check_for_python()
{
	which python 2> /dev/null
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "python is not installed, please install." 1
	fi 
	python_version=`python --version`
	echo "Running with python version: ${python_version}"
	echo "Zathras developed using python version:  3.7.4"
	report_util_version python_version "${python_version}"
}

check_for_aws()
{
	aws_version=`dnf list installed | grep awscli.noarch`
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "aws requires the aws clis to be installed\ndnf install -y awscli" 1
	fi
	report_util_version aws_version "${aws_version}"
}

check_for_boto()
{
	boto_version=`pip3 list --format="columns" | grep -F boto`
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "boto modules need to be installed.\npip3 install -U boto --user" 1
	fi 
	report_util_version boto_version "${boto_version}"
}

check_for_pip3()
{
	pip3_version=`pip3 --version`
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "pip3 command needs to be installed.\ndnf install -y python3-pip" 1
	fi
	report_util_version pip3_version "${pip3_version}"
}

check_for_terraform()
{

	terraform_version=`terraform --version | head -1`
	if [[ $? -eq 1 ]]; then
		cleanup_and_exit "terraform command needs to be installed.\n" 1
	fi
	report_util_version terraform_version "${terraform_version}"
}

#
# Check the packages to see if they are installed on the system.
# If not, we flag the issue and bail.
#
package_check()
{
	check_for_pip3
	check_for_boto
	check_for_ansible
	check_for_yq
	check_for_jq
	check_for_python
	if [[ $gl_system_type == "aws" ]]; then
		check_for_aws
	fi
	check_for_terraform
}

#
# Report error with boolean setting.
#
bool_error()
{
	if [[ $1 != "0" ]] && [[ $1 != "1" ]] ; then
		cleanup_and_exit "Error $1 invalid value for $2, valid values are 0 and 1" 1
	fi
}

#
#  Verify that the terminate value is a boolean.
#
verify_terminate_value()
{
	bool_error $1 cloud_terminate
}

#
#  Verify that the ssh key file is present.
#
verify_ssh_key_file()
{
	if [[ ! -f $1 ]]; then
		cleanup_and_exit "Error: ssh key file $1 does not exist." 1
	fi
}

#
#  Verify that the test def file is present.
#
verify_test_def_file()
{
	if [[ ! -f $1 ]]; then
		cleanup_and_exit "Error: test def file $1 does not exist." 1
	fi
}

#
# Verify that the os_vendor provided is one of the values in $valid_os_vendors
#
verify_os_vendor()
{
	os_vendor_found=0

	for os_vendor_check in  $gl_valid_os_vendors; 
	do
		if [[ $1 == $os_vendor_check ]]; then
			os_vendor_found=1
		fi
	done
	if [[ $os_vendor_found -eq 0 ]]; then
		cleanup_and_exit "Error: $1, is an unrecognized OS vendor.  Possible values are: $gl_valid_os_vendors" 1
	fi
}

#
# Verify that the system type provided, is one of the values in $gl_valid_system_types
#
verify_system_type()
{
	sys_type_found=0

	for sys_type in $gl_valid_system_types; 
	do
		if [[ $1 == $sys_type ]]; then
			sys_type_found=1
		fi
	done
	if [[ $sys_type_found -eq 0 ]]; then
		cleanup_and_exit "Error: $1, is an unrecognized system type.  Valid system types are designated via --system_type.  Valid system types are $gl_valid_system_types" 1
	fi
}

#
# Verify that the force_upload variable is a boolean value.
#
verify_force_upload_value()
{
	bool_error $1 force_upload
}

#
# Verify that the value set for selinux is either enabled or disabled.
#
verify_selinux_state()
{
	if [[ $1 -ne "enabled" ]] && [[ $1 -ne "disabled" ]]; then
		cleanup_and_exit "Error: $1, is an unrecognized selinux state value.  Valid values are enabled/disabled" 1
	fi
}

#
# Verify that the value set for selinux level  is either enforcing, permissive or disabled.
#
verify_selinux_level()
{
	if [[ $1 -ne "enforcing" ]] && [[ $1 -ne "disabled" ]] && [[ $1 -ne "permissive" ]]; then
		cleanup_and_exit "Error: $1, is an unrecognized selinux level value.  Valid values are enforcing/permissive/disabled" 1
	fi
}

#
# Ubuntu we do not do enforcing.  Issue is Ubuntu does not have it on by default and to get everything to work properly
# requires a lot of work, and long reboot times.
#
verify_selinux()
{
	if [[ $gl_os_vendor == "ubuntu" ]] && [[ $gl_selinux_state == "enabled" ]] && [[ $gl_selinux_level == "enforcing" ]]; then
		cleanup_and_exit "Error: We do not support enforcing with selinux on ubuntu" 1
	fi
}

#
# Verify iterations is a positive number, > 1
#
verify_iterations()
{
	value_check=$(($1 + 0))
	if [[ $value_check -lt 1 ]]; then
		cleanup_and_exit "Error: $1, iterations needs to be an integer and greater than 0" 1
	fi
}

#
# Verify that the java version provided is a valid value.
#
verify_java_version()
{
	java_vers=`grep java_version java_info  | cut -d\" -f 4`

	for ask_for in $1;
	do
		found=0
		for version in $java_vers; 
		do
			if [[ $version == $ask_for ]]; then
				found=1
			fi
		done
		if [[ $found -eq 0 ]]; then
			cleanup_and_exit "Error: unknown java version $1, known versions are: $java_vers" 1
		fi
	done
	
}

obtain_network_info()
{
	entry=$1

	networks_string=`bin/parse_net_line \"${entry}\"`
	entries=`echo $networks_string | wc -w`
	if [ $entries -lt 2 ]; then
		cleanup_and_exit "$entry\nYou designated networks, but did not provide the number of networks, or the system to connect to.  Please resolve, aborting." 1
	fi
	gl_cloud_net_type=`echo $networks_string | cut -d' ' -f1`
	if [[ $entry == *"Number"* ]]; then
		gl_networks_present=`echo $entry | cut -d'=' -f2`
	else
		gl_cloud_networks_sys=`echo $networks_string | cut -d' ' -f2- | sed "s/\"//g" | sed "s/ EndList//g"`
		gl_networks_present=`echo $gl_cloud_networks_sys | wc -w`
	fi
}

#
# Verify that the host config is valid, and has sane values.
#
verify_host_config()
{
	verify_config=`echo $1 | sed "s/,/ /g"`
	gl_disks_present=0

	for entry in $verify_config; do
		vm_instance=`echo $entry | cut -d':' -f 1`
		if [[ $gl_system_type == "aws" ]]; then
			aws ec2 describe-instance-types --instance-types $vm_instance > /dev/null
			if [[ $? -ne 0 ]]; then
				cleanup_and_exit "Error: AWS, unknown instance" 1 $vm_instance
			fi
		fi
		if [[ $gl_system_type == "gcp" ]]; then
			gcloud compute machine-types describe $vm_instance > /dev/null
			if [[ $? -ne 0 ]]; then 
			    cleanup_and_exit "Error: GCP, unknown instance" 1 $vm_instance
			fi
		fi
		if [[ $gl_system_type == "azure" ]]; then
			# change eastus to be a value
			az vm list-sizes --location "${gl_cloud_region}" | grep -o $vm_instance
			if [[ $? -ne 0 ]]; then 
			    cleanup_and_exit "Error: azure, unknown instance $vm_instance" 1
			fi
		fi
		if [[ $entry == *"Disks"* ]] && [[ $gl_disks_present == "0" ]]; then
			gl_disks_present=`bin/parse_disk_line \"$entry\" | cut -d':' -f4`
			if [[ $gl_disks_present == "0" ]]; then
				if [[ $entry == *"type=internal"* ]]; then
					gl_internal_disks=1
				else
					cleanup_and_exit "$entry\nYou designated Disks, but gave a zero count of disks.  Please resolve, aborting." 1
				fi
			fi
		fi

		if [[ $entry == *"CPU_type"* ]]; then
			gl_cpu_type_request=`echo $entry | cut -d';' -f 2`
		fi

		if [[ $entry == *"Cloud_Placement"* ]]; then
			gl_cloud_placement=`echo $entry | cut -d';' -f 2`
		fi

		if [[ $entry == *"Network"* ]]; then
			obtain_network_info $entry
		fi
	done
}

#
# Goes through the data values and verifies the settings.
#
verify_data()
{
	if [[ $2 != "" ]]; then
		for value in $2;
		do
			$1 $value
		done
	fi
}

#
# Remove the duplicate options.  The last appearance of the option will override any earlier
# option in the list.  This is part of the override operation for test_defs.yml.
#
# $1: Is the file containing the options
#
run_burden_remove_dups()
{
	#
	# Read the file in and replace all -- with ##.  We do that, because there are string values
	# to the options that may contain a - in it.
	#
	command=`cat $1 | sed "s/--/##/g"`
	chars=`echo $command | awk -v RS='#' 'END{print NR}'`

	#
	# Build the option list backwards now.
	#
	index=2
	field_back=""
	field_separ=""
	while [ $index -lt $chars ]
	do
		let "next=$index+1"
		field=`echo $command | cut -d'#' -f$next`
		field_back=${field}${field_separ}${field_back}
		field_separ="#"
		let "index=$index+2"
	done

	#
	# Now rebuild, drop options that already have been specified.
	#
	chars=`echo $field_back | awk -v RS='#' 'END{print NR-1}'`
	index=1
	new_string=""
	while [ $index -le $chars ];
	do
		data=`echo $field_back | cut -d'#' -f $index`
		option=`echo $data | cut -d' ' -f 1`
		if [[ $new_string != *"--${option} "* ]];then
			new_string=${new_string}--${data}" "
		fi
		let "index=${index}+1"
	done
	quote=0
	real_string=""
	field_separ=""
	for fix_it in $new_string; do
		if [[ $quote -eq 1 ]]; then
			real_string=${real_string}${field_separ}\"${fix_it}\"
			quote=0
		else
			real_string=${real_string}${field_separ}${fix_it}
		fi
		field_separ=" "
		if [[ $fix_it == *"host_config"* ]]; then
			quote=1
		fi
	done
	#
	# Overwrite the file with the new set of options.
	#
	echo ./burden --test_def_file  $gl_test_def_dir/full_test_defs.yml $real_string > $1
}

replace_scenario_vars()
{
	list=`grep ^% $gl_scenario_to_run | sed "s/% //g"`
	if [[ $list != "" ]]; then
		scenario_wrk_file1=$(mktemp /tmp/zath_convert_scen.XXXXXX)
		scenario_wrk_file2=$(mktemp /tmp/zath_convert_scen.XXXXXX)
		cp $gl_scenario_to_run $scenario_wrk_file1
		for i in $list; do
			string=`echo $i | sed "s/\//+++/g"`
			replace=`echo $string | cut -d'=' -f 1`
			with=`echo $string  | cut -d'=' -f 2-`
			sed "s/${replace}/${with}/g" $scenario_wrk_file1 > $scenario_wrk_file2
			mv  $scenario_wrk_file2 $scenario_wrk_file1
		done
		grep -v  "^%" $scenario_wrk_file1 > ${gl_scenario_to_run}_cnvt
		gl_scenario_to_run=${gl_scenario_to_run}_cnvt
		rm -rf  scenario_wrk_file2 scenario_wrk_file1
	fi
}

# Convert the scenario file to yml format.  Any line that starts with a '#' is a comment.
# Any line that starts with a '%' is a replacement in the format of
# % <string replacing>=<new string>
#
convert_scenario_file()
{
	#
	# First build the sed list
	# We replace all / in the strings with +++ to process,
	# when done we convert them back to /.  This is done because
	# sed does not handle / in the strings very well, and to
	# escape it, things get messy fast.
	#

	scenario_cnvt_file=$(mktemp /tmp/zath_convert.XXXXXX)
	sed "s/;/----/g" $1 > $scenario_cnvt_file
	sed_string="cat $scenario_cnvt_file"
	list=`grep ^% $scenario_cnvt_file | sed "s/% //g"`
	#
	# Filter out comments and the assignments
	#
	sed_string="${sed_string} | grep -v ^#"
	#
	# Now create the parse file to use.
	#
	echo "${sed_string}" > parse_reduce
	chmod 755 parse_reduce

	tmp_run_file=$(mktemp /tmp/zath_temp_run.XXXXXX)
	./parse_reduce | sed "s/+++/\//g" > $tmp_run_file
	cat $tmp_run_file | yq .  > parse_file.tmp
	if [ $? -ne 0 ]; then
		cleanup_and_exit "Creation of the parse_file via yq failed" 1
	fi
	#
	# Verify the file just created is valid.
	#
	sed "s/----/;/g" parse_file.tmp > parse_file
	python -c 'import yaml, sys; print(yaml.safe_load(sys.stdin))' < parse_file
	if [ $? -eq 1 ]; then
		cleanup_and_exit "The file, parse_file does not meet yaml requirements." 1
	fi
	#
	# Check to make sure we have the proper number of host configs
	# 
	sc_cnt=`grep host_config $tmp_run_file |  wc -l`
	ps_cnt=`grep host_config parse_file.tmp | wc -l`
	if [ $ps_cnt != $sc_cnt ]; then
		cleanup_and_exit "yq did not find the appropriate number of hosts, look for duplicate names" 1
	fi
	rm $tmp_run_file $scenario_cnvt_file
}

#
# Parse the passed scenario
#
# For each test in the scenario file, parse the test information, create the cli to be passed to burden.
# Once we have the cli, create a new burden process, passing in --child with it.  Repeat for each test until
# we hit a host_config of SYS_BARRIER or end of the file.  Wait for all processes we started to finish, and then
# either exit out, or execute the next set of tests.
#
run_scenario()
{
	declare -a pids
 	update_target_uploaded=0
	override_options=""
	override_options_gl=""
	over_gl_separ=""
	pindex=0
	declare -a globals
	declare -a test_values
	scenario=$1
	test_cli="--max_systems ${gl_max_systems}"

	#
	# Check to see if the scenario file exists.
	#
	if [[ ! -f "$scenario" ]]; then
		cleanup_and_exit "Scenario ${scenario} not found." 1
	fi

	#
	# Convert the scenario file.  After this the scenario will point to the parsed
	# file
	convert_scenario_file $scenario
	scenario=parse_file

	#
	# Verify all tests that are present are valid tests.
	#
	verify_gl_test_list=`grep \"tests\": parse_file | cut -d\" -f 4`
	for i in $verify_test_list;
	do
		verify_test $i
	done

	#
	# Obtain global values
	#
	doing_global=0
	gindex=0
	field_separ=""
	while IFS= read -r line
	do
		setting=`echo $line | sed "s/\"//g" | xargs echo -n`
		if [[ $setting == "}," ]]; then
			break
		fi
		if [[ $setting == "global: {" ]]; then
			doing_global=1
			continue
		fi
		if [[ $doing_global -eq 0 ]]; then
			continue;
		fi
		field_value=`echo $setting | sed "s/://" | sed 's/,$//'`
		if [[ $field_value == *"update_target"* ]]; then
			gl_update_target=`echo $field_value | cut -d' ' -f 2`
			update_target_uploaded=1
		fi
		#
		# We do not include test_def_file option here.  It has already
		# been processed and we use full_test_defs.yml.
		#
		if [[ $field_value == "test_def_file"* ]]; then
				continue;
		fi
		globals[${gindex}]=$field_separ\"--$field_value\"
		let "gindex=$gindex+1"
		field_separ=" "
	done < "$scenario"
	if [[ $update_target_uploaded -eq 1 ]]; then
		update_the_image $gl_update_target
	fi
	if [[ $gl_test_override_options == *"global:"* ]]; then
		for i in $gl_test_override_options; do
			if [[ $i == *"global:"* ]]; then
				override_options_gl=`echo $i | cut -d: -f 2- | sed "s/,/ /g"`
				over_gl_separ=" "
				break
			fi
		done
	fi
	unset test_values
	test_index=0
	sys_index=0

	#
	# Now the individual systems.  Contents of system, will override anything in
	# Global section
	#
	while IFS= read -r line
	do
		setting=`echo $line | sed "s/\"//g" | xargs echo -n`
		#
		# Keep looking until we hit the systems block.
		#
		if [[ $sys_index -eq 0 ]]; then
			if [[ $setting == "systems: {" ]]; then
				sys_index=1
			fi
			continue;
		fi
		#
		# We are now looking for an actual system entry.
		#
		if [[ $setting == *"system"*": {" ]]; then
			sysname=`echo $setting | cut -d: -f1 | sed "s/ //g"`
			override_options=$override_options_gl
			if [[ $gl_test_override_options == *"${sysname}:"* ]]; then
				for i in $gl_test_override_options; do
					if [[ $i == *"${sysname}:"* ]]; then
						override=`echo $i | cut -d: -f 2- | sed "s/,/ /g"`
						override_options=${override_options}${over_gl_separ}${override}
						break
					fi
				done
			fi
			continue
		fi

		#
		# If we hit the end of the test, then finish the cli and call back into burden
		# with the CLI.  Else keep parsing the lines.
		#
		if [[ $setting == "}," ]] || [[ $setting == "}" ]]; then
			for i in "${globals[@]}"; do
				arg_value=`echo $i | cut -d'"' -f2`
				argument=`echo $arg_value | cut -d' ' -f 1`
				if [[ ! " ${test_values[@]} " =~ " ${argument} " ]]; then
					test_cli=$test_cli" "$arg_value
				fi
			done
			#
			# Set the local values.
			#
			for i in "${test_values[@]}"; do
				arg_value=`echo $i | cut -d'"' -f2`
				if [[ $arg_value == *"--}"* ]]; then
					continue
				fi
				if [[ $arg_value == *"--host_config"* ]]; then 
					argument=`echo $arg_value | cut -d' ' -f 2`
					test_cli=$test_cli" --host_config \"${argument}\""
				fi
				if [[ $arg_value == *"update_target"* ]]; then
					if [[ $update_target_uploaded -eq 0 ]]; then
						update_the_image $gl_update_target
						update_target_uploaded=1
					fi
				else
					test_cli=$test_cli" "$arg_value
				fi
			done
			#
			# Add the entries that are designated from the CLI to the end.  Entries
			# at the end will override the options if they are passed back to burden.
			# Later we will remove the earlier options.
			#
			for i in `cat $gl_cli_supplied_options`
			do
				test_cli=$test_cli" "$i
			done

			#
			# Now add the items that are being overridden for the test itself.
			#
			if [[ $override_options != "" ]]; then
				for i in $override_options; do
					field1=`echo $i | cut -d'=' -f1`
					field2=`echo $i | cut -d'=' -f2`
					if [[ $field1 != $field2 ]]; then
						test_cli="${test_cli} --${field1} ${field2}"
					else
						test_cli="$test_cli --${field1}"
					fi
				done
			fi

		
			#
			# Have the line now, run the command.
			#
			test_cli=$test_cli" --dir_index ${sys_index} --child"
			let "sys_index=$sys_index+1"
			sysexpect="system"$sys_index":"
			if [[ $gl_use_spot -eq 1 ]]; then
				test_cli="${test_cli} --use_spot 1"
			fi
			#
			# Host config causing issues with calling burden directly.  So as a workaround
			# we will dump the command to a file, and run it from there.
			#
			if [[ $test_cli == *"SYS_BARRIER"* ]]; then
				#
				# Wait for all outstanding tests to finish before we do more.
				#
				if [ $pindex != 0 ]; then
					for pid in ${pids[*]}; do
						wait $pid
					done
				fi
				pindex=0
				pid=""
			else
				tmpfile=$(mktemp /tmp/zath_temp_test_cli.XXXXXX)
				echo "#!/bin/bash" > $tmpfile
				echo ./burden $test_cli --run_file run_burden_${pindex}  > $tmpfile
				#
				# Remove duplicate entries.
				#
				run_burden_remove_dups $tmpfile
				mv $tmpfile run_burden_${pindex}
				chmod 755 run_burden_${pindex}
			 	./run_burden_${pindex} &
				pids[${pindex}]=$!
				let "pindex=$pindex+1"
			fi
			#
			# Done with this test, reset and continue.
			#
			unset test_values
			test_index=0
			test_cli="--max_systems ${gl_max_systems}"
			#
			# if at the end of the file, break out.
			#
			if [[ $setting == "}" ]]; then
				break
			fi
		fi
		#
		# take the entry and convert it to its cli equivalent.
		#
		cli_value=`echo $setting | sed "s/://" | sed 's/,$//'`
		test_values[${test_index}]=" --$cli_value"
		let "test_index=$test_index+1"
	done < "$scenario"
	#
	# Wait for everyone to finish up.
	#
	for pid in ${pids[*]}; do
		wait $pid
	done
	if [[ $gl_update_target != $value_not_set ]]; then
		$UTILS_DIR/cleanup_install_lock $BASHPID
	fi
}

#
# Verify the contents of full_test_defs.yml is somewhat sane.
#
# $1: the file checking.
# $2: the base file that was used for creating.
#
verify_test_configuration()
{
	config_file=$1
	base_config=$2
	verify_tmp_file=$(mktemp /tmp/zath_temp_verify_test.XXXXXX)
	bail_out=0
	#
	# First, make sure the test name is unique.  This protects
	# against 
	# test_defs:
	#   test1:
	#     < test info>
	#   test1:
	#
	grep "^  test" $config_file > $verify_tmp_file

	total_tests=`wc -l $verify_tmp_file | cut -d ' ' -f 1`
	dist_tests=`sort -u $verify_tmp_file | wc -l`

	if [[ $total_tests -ne $dist_tests ]]; then
		cleanup_and_exit "Error: Appears you have tests that have the same index value, please correct the file ${base_config}." 1
	fi

	#
	# If asking to check the test version, verify the versions exist, and
	# is the latest.
	#
	if [[ $gl_test_version_check -eq 1 ]] || [[ $gl_update_test_versions -eq 1 ]]; then
		pushd config > /dev/null
		if [[ $gl_test_version_check -eq 1 ]]; then
			echo Git version check.
			printf '%32s%10s%10s%6s\n' "Test" "Using" "latest" "Ok"
		else
			echo updating test versions
		fi
		for test_repo in `ls *yml`; do
			if [[ $test_repo == "full_test_defs.yml" ]] ||
			   [[ $test_repo == "java_pkg_def.yml" ]] ||
			   [[ $test_repo == "default_template.yml" ]] ||
			   [[ $test_repo = "test_defs.yml" ]] ||
			   [[ $test_repo = "install_pbench_vars.yml" ]] ||
			   [[ $test_repo = "verify.yml" ]]; then
				continue;
			fi
			using_version=`grep repo_file $test_repo | cut -d':' -f2 | sed "s/.zip//g" |cut -d'"' -f2`
			location=`grep location: ${test_repo} | cut -d: -f2- | sed "s/ //g"`
			if [[ $location == "https://github.com"* ]]; then
				repo=`echo $location | cut -d'/' -f 1-5`
				git -c 'versionsort.suffix=-' ls-remote --exit-code --refs --sort='version:refname' --tags $repo | rev | cut -d'/' -f1 | rev >  git_vers
				#
				# Make sure the tag we want is present
				#
				version_fail=""
				grep ${using_version} git_vers > /dev/null
				if [ $? -ne 0 ]; then
					version_fail="$repo, version $using_version is not defined."
					bail_out=1
				fi
				latest=`tail -1 git_vers`
				if [[ $using_version != $latest ]]; then
					version_ok="no"
				else
					version_ok="yes"
				fi
				if [[ $gl_update_test_versions -eq 0 ]]; then
					printf '%32s%10s%10s%6s\n' $test_repo $using_version $latest $version_ok
					if [[ $version_fail != "" ]]; then
						echo Failure: $version_fail
					fi
				else
					if [[ $version_ok == "no" ]]; then
						#
						# We have to walk the file instead of using a series of sed pipes.
						# The reasons for this are:
						#  1) We can not simply update the version number through the whole
						#     file, we might change something we should not.  For example,
						#     if an option passed to the test happens to match the current
						#     version number in the file.
						#       Example:
						#         exec_dir: "test-wrapper-1.0/test"
						#         repo_file: "v1.0.zip"
						#         test_specific: "--option burden_version_1.0
						#  2) If we do a full sed replacement, if there are extra spaces
						#     in the line, we will not change it.
						#  3) We could pull the required string via grep, and build the new
						#     one.  However that will require reading the file 3 times (2
						#     greps, and then one update), versus the one read if we simply
						#     walk the file, and look for the line to replace.
						#
						echo Updating version for $test_repo from $using_version to $latest
						while IFS= read -r replace_line
						do
							if [[ $replace_line == "repo_file:"* ]]; then
								echo $replace_line | sed "s/$using_version/$latest/g" >> ${test_repo}.new
								continue
							fi
							if [[ $replace_line == "exec_dir:"* ]]; then
								replace_with=`echo $latest | sed "s/^v/-/g"`
								replacing=`echo $using_version | sed "s/^v/-/g"`
								echo $replace_line | sed "s/$replacing/$replace_with/g" >> ${test_repo}.new
								continue
							fi
							echo $replace_line >> ${test_repo}.new
						done < "${test_repo}"
						mv $test_repo ${test_repo}.orig
						mv ${test_repo}.new ${test_repo}
					fi
				fi
				rm -rf $temp_dir 
			else
				echo $test_repo, Only github is supported.
			fi
		done
		popd > /dev/null
		if [ $gl_update_test_versions -eq 1 ]; then
			cleanup_and_exit "Update of test versions completed" 0
		fi
	fi

	#
	# Verify any upload_extra files.  They are expected to be local on the system
	#

	while IFS= read -r fline
	do
		if [[ $fline == *" test_name:"* ]]; then
			test_name=`echo $fline | awk '{print $2}'`
			continue
		fi
		if [[ $fline != *" upload_extra:"* ]]; then
			continue
		fi
		file=`echo $fline | awk '{print $2}'`
		if [[ $file == \""none\"" ]] || [[ $file == \""<replace with kit location>\"" ]]; then
			continue
		fi
		file_check=`echo $file | sed "s/\"//g" | sed "s/,/ /g"`
		for file in $file_check; do
			if [[ ! -f "$file" ]]; then
				if [[ $gl_scenario_to_run != "" ]]; then
					grep -q $test_name $gl_scenario_to_run
					rtc=$?
				else
					 echo $gl_test_list_out | grep -q
					 rtc=$?
				fi
				#
				# Bail only if we are suppose to run the associated test.  Else
				# simply issue a warning.
				#
				echo test: $test_name
				if [ $rtc -eq 0 ]; then
					cleanup_and_exit "Error: Upload extra file $file not found." 1
				else
					echo Warning: Upload extra file $file not found.
				fi
			fi
		done
	done < "${config_file}"
	#
	# Verify test_run_from field.  Valid values is local and remote
	#
	grep "^    test_run_from:" $config_file | cut -d':' -f 2 | sed "s/^ //g" > $verify_tmp_file
	while IFS= read -r fline
	do
		if [[ $fline == "\"remote\"" ]]; then
			continue
		fi
		if [[ $fline == "\"local\"" ]]; then
			continue
		fi
		cleanup_and_exit "Error: Unknown test_run_from value: $fline" 1
	done < "${verify_tmp_file}"
	rm ${verify_tmp_file}
	if [ $bail_out -eq 1 ]; then
		cleanup_and_exit "Error: At least one get tag is not known." 1
	fi
}
#
# We read in the template file for the test, and for each line that is not
# defined in test_defs.yml we use.  If the line appears in both the template
# file and test_defs.yml, then we use the entry in test_defs.yml.
#
#  $1: Location of the template file
#  $2: The config file being built.
#  $3: If set to 1, then we are reading in a template file. If 0 then simply
#      use what is in test_defs.yml
#  $4: The test definition directory.
#
process_test_template_data()
{
	tmpfile=$1
	temp_def=$2
	expansion_required=$3
	cfg_dir=$4
	new_file=$(mktemp /tmp/zath_temp_template.XXXXXX)

	if [[ $expansion_required -eq 1 ]]; then
		temp=`grep "test_template:" $tmpfile | cut -d: -f 2 | sed "s/ //g"`
		if [[ $? -ne 0 ]]; then
			file_template=""
		else
			file_template=$4/$temp
		fi
		#
		# Set up for defaults
		#
		if [[ ! -f "${4}/default_template.yml" ]]; then
			default_template=""
		else
			default_template=${4}/default_template.yml
		fi

		while IFS= read -r fline
		do
			if [[ $fline != "" ]]; then
				echo "$fline" >> $new_file
			fi
		done < "${tmpfile}"
		if [[ $file_template != "" ]]; then
			while IFS= read -r fline
			do
				look_for=`echo $fline | cut -d: -f 1`
				grep ${look_for}: $tmpfile >2 /dev/null
				if [[ $? -eq 1 ]]; then
					echo "    ${fline}" >> $new_file
				fi
			done < $file_template
		fi
		if [[ $default_template != "" ]]; then
			while IFS= read -r fline
			do
				look_for=`echo $fline | cut -d: -f 1`
				grep ${look_for}: $new_file >2 /dev/null
				if [[ $? -eq 1 ]]; then
					echo "    ${fline}" >> $new_file
				fi
			done < $default_template
		fi
		rm $tmpfile
	else
		mv  $tmpfile $new_file
	fi
	#
	# We have an order that is expected for certain things.  Put it all in that order as
	# indicated by the file entry_order.
	# Format of the entry_order file
	# 
	# ^  test
	# ^    test_template:
	#
	# An entry for each expected item.  The ^ indicates start of line.
	#
	while IFS= read -r new_line
	do
		grep "$new_line" $new_file >> $temp_def
	done < "${gl_test_def_dir}/entry_order"
	#
	# Remove any comments.
	#
	grep -v ^# $temp_def > $new_file
	mv $new_file $temp_def
	echo "" >> $temp_def
}

#
# Take the templates and the test_defs.yml and generate the actual test config to use.
#
# $1: The base test def to use.  The templates are expected to reside in the same directory
#     as base test def file.
#
integrate_templates()
{
	first_line=0
	working=0
	tmpfile=$(mktemp /tmp/zath_temp_test_template.XXXXXX)
	temp_def=$(mktemp /tmp/zath_temp_full_template.XXXXXX)
	expansion_required=0

	if [[ ! -f "${gl_test_def_dir}/test_defs.yml" ]]; then
		cleanup_and_exit "did not find file  ${gl_test_def_dir}/test_defs.yml" 1
	fi

	chars=`echo $1 | awk -v RS='/' 'END{print NR-1}'`
	gl_test_def_dir=`echo $1 | cut -d'/' -f 1-${chars}`

	if [[ $gl_first_invocation -eq 1 ]]; then
		rm $gl_test_def_dir/full_test_defs.yml 2> /dev/null
	fi
	if [[ ! -f $gl_test_def_dir/full_test_defs.yml ]]; then
		while IFS= read -r line
		do
			if [[ $first_line -eq 0 ]]; then
				echo "${line}" >> $tmpfile
				first_line=1
				continue
			fi
			if [[ $line = "  test"* ]]; then
				if [[ $working -eq 1 ]]; then
					process_test_template_data $tmpfile $temp_def $expansion_required $gl_test_def_dir
					expansion_required=0
				fi
				echo "${line}" >> $tmpfile
				working=1
				continue;
			fi
			if [[ $line = *"test_template:"* ]] && [[ $line != *"none"* ]]; then
				expansion_required=1
			fi
			echo "${line}" >> $tmpfile
		done < "$1"
		#
		# Do not forget the last item
		#
		process_test_template_data $tmpfile $temp_def $expansion_required $gl_test_def_dir
		cp $temp_def ${gl_test_def_dir}/full_test_defs.yml

		#
		# Now verify the test config generated.
		#
		verify_test_configuration $gl_test_def_dir/full_test_defs.yml $1 1
	fi
	rm $temp_def 2> /dev/null
	rm $tmpfile 2> /dev/null
}

#
# List the active systems created by tf
#
tf_list()
{
	dirs=`find . -type d | grep terraform.tfstate.d | rev  | cut -d'/' -f3- | rev | grep tf`
	for tf_show in $dirs; do
		pushd $tf_show > /dev/null
		terraform show > tf_list_info
		grep subnet tf_list_info >& /dev/null
		if [ $? -eq 0 ]; then
			work_dir=`pwd | rev | cut -d'/' -f 2 | rev`
			grep  azure tf_list_info >& /dev/null
			if [ $? -eq 0 ]; then
				vm_size=`grep size tf_list_info | grep -v disk | cut -d'"' -f2`
				public_ip=`grep public_ip_address tf_list_info | head -1 | cut -d'"' -f2 | sort -u`
				name_tag=`grep environment tf_list_info | cut -d'"' -f4 | sort -u`
				printf "work_dir: %s\n" $work_dir
				printf "\tfull_path: %s\n" $tf_show
				printf "\tvm_size: %s\n" $vm_size
				printf "\tpublic_ip: %s\n" $public_ip
				printf "\tname_tag: %s\n" $name_tag
			fi
			grep  aws tf_list_info >& /dev/null
			if [ $? -eq 0 ]; then
				vm_size=`grep instance_type tf_list_info | cut -d'"' -f2`
				inst_state=`grep instance_state tf_list_info | cut -d'"' -f2`
				public_dns=`grep public_dns tf_list_info | cut -d'"' -f2 | sort -u`
				name_tag=`grep Name tf_list_info | cut -d'"' -f4 | sort -u`
				printf "work_dir: %s\n" $work_dir
				printf "\tfull_path: %s\n" $tf_show
				printf "\tvm_size: %s\n" $vm_size
				printf "\tinstance_state: %s\n" $inst_state
				printf "\tpublic_dns: %s\n" $public_dns
				printf "\tname_tag: %s\n" $name_tag
			fi
		fi
		rm tf_list_info
		popd > /dev/null
	done
	exit
}
#
# Walk all the tf directories and attempt to remove the instance.
#
tf_terminate()
{

	if [[ $gl_tf_term_list == "" ]]; then
		dirs=`find . -type d | grep terraform.tfstate.d | rev  | cut -d'/' -f3- | rev | grep tf`
	else
		dirs=`echo $gl_tf_term_list | sed "s/,/ /g"`
		echo $gl_tf_term_list
		echo $dirs
	fi
	for tf_del in $dirs; do
		pushd $tf_del > /dev/null
		terraform plan -var-file=env.tfvars -destroy -out=destroy.tfplan
		if [ $? -eq 0 ]; then
			terraform apply "destroy.tfplan"
			#
			# Now get arid of the tf directory.
			#
			if [ $gl_tf_terminate -eq 0 ]; then
				cd ..
				rm -rf tf
			fi
		else
			echo Warning: Unable to create the plan for $tf_del
		fi
		popd > /dev/null
	done
	exit
}

#
# If the test_def_dir has https or git in it, we will pull from
# the git repo.  If not simply check that the file exists.
#
handle_test_defs()
{
	if [[ $gl_test_def_dir == "https:"* ]] || [[ $gl_test_def_dir == "git:"* ]]; then
		timeout $gl_git_timeout git clone ${gl_test_def_dir} test_configs 2> /dev/null
		if [ $? -ne 0 ]; then
			cleanup_and_exit "Unable to clone the test configs, $gl_test_def_dir" 1
		fi
		gl_test_def_dir="${gl_top_dir}/test_configs"

	fi
	verify_data verify_test_def_file ${gl_test_def_dir}/test_defs.yml
}

#
# Usage information. 
#
usage()
{
	echo "Usage: $0"
	echo "Version: "$version
	echo "General options"
	echo "  --archive <dir>/<results>:  location to save the archive information to"
	echo "  --child: tells burden it is a child of another burden process and not to"
	echo "    perform the initial setup work"
	echo "	--create_attempts: number of times we attempt to create an instance to get the"
	echo "    designated cpu type"
	echo "  --git_timeout: Number of seconds to timeout on git requests.  Default is 60"
	echo "  --system_type <vendor>: aws, azure, gcp, or local"
	echo "  --host_config <config options>: Specification of the system and configuration"
	if [[ $1 -eq 1 ]]; then
		echo "    If the --system_type option is local, then this is simply the system name"
		echo "    to run on, and it will pull the config value from the file <hostname>.conf"
		echo "    in local_configs"
		echo "      local_configs format:"
		echo "        server_ips:  <xx.xx.xx.xx>,<xx.xx.xx.xx>"
		echo "        client_ips: <xx.xx.xx.xx>,<xx.xx.xx.xx>"
		echo "        storage: /dev/nvme2n1,/dev/nvme1n1"
		echo ""
		echo "    If the --system_type option is a cloud type, then the following may"
		echo "    be specified"
		echo "      config_file format:"
		echo "        Fields definition:"
		echo "          instance_type: The cloud instance (ie i3en.xlarge)."
		echo "            [region=<value>&zone=<value>] is totally optional"
		echo "            region: the region the cloud is created in. The default is"
		echo "               whatever the user's default region is."
		echo "            zone: The zone in the region the cloud is to be created in, if not specified"
		echo "                  will randomly pick one"
		echo "          number_networks: number of internal networks to create,    If designated a second"
		echo "                  system of the same configuration is created to connect the network to."
		echo "          sysctl_settings: files in sysctl_setting to use.  Each file"
		echo "                  sets a set of tunables, separator is +"
		echo "          number_of_disks: How many disks to create and attach"
		echo "          disk_size: How large is the disk in gigabytes"
		echo "          disk_type: Type of disk to be created"
		echo ""
		echo "      <instance>:<Cloud_Placement>&<CPU_type>&<Disks>&<Networks>&<Sysctl_settings>&<Cloud_Placement>"
		echo "        Fields definition:"
		echo "          <instance[region=<val>&zone=<val]>: The cloud instance name (ie i3en.xlarge)."
		echo "            includes region and zone requests, both are optional."
		echo "          <Cloud_Placement=value>"
		echo "            value is specific to each cloud, depending on their definition.  For the placement"
		echo "            name see the documenation for the cloud being designated. Default value is none"
		echo "          <CPU_type=value>"
		echo "             value is a string that is provided by the user that has to match a substring in the output"
		echo "             from lscpu field, Model name:"
		echo "          <Disks;number=n;size=n;type=n>"
		echo "             number: How many disks to create and attach"
		echo "             size: How large is the disk in gigabytes"
		echo "             type: Type of disk creating"
		echo "          <Networks;<system>;<system>;....;type=x"
		echo "             <system>: in case of cloud systems, it is the VM to use.  In case of local systems, it will"
		echo "             be the name of the system working with.  In the case of the cloud, if the second system"
		echo "		   is not designated, we will use the original vm type."
                echo "             type:"
		echo "               default, uses the default cloud network type"
                echo "               public, uses the public dns connections"
                echo "               cloud specific, specific to each cloud"
		echo "          <Sysctl_settings=n+n...>"
		echo "            sysctl_settings: files in sysctl_setting to use.  Each file"
		echo "            sets a set of tunables, separator is +"
		echo "       System config file Examples"
		echo "         Example 1: Designate 2 systems, no config options"
		echo "           m5.xlarge,m5.4xlarge"
		echo "         Example 2: Designate m5.24xlarge, 8 gp2 disks of 1200 Gig"
		echo "           m5.24xlarge:Disks;number=8;size=1200;type=gp2"
		echo "         Example 3: Designate m5.24xlarge with sys tunings udp_fix and none"
		echo "           m5.24xlarge:Sysctl_settings=none+udp_fix"
		echo "         Example 4: Designate m5.xlarge to be created in us-east-1 and zone b"
		echo "           \"m5.xlarge[region=us-east-1&zone=b]\""
		echo "         Example 5: Designate two different systems connected vial networks."
		echo "           m5.xlarge:Networks;m5.2xlarge"
	fi
	echo "  --ignore_repo_errors: If present we will ignore repo errors. The default is to abort the run"
	echo "    when a repo error occurs."
	echo "  --individ_vars: Contains various burden settings.  Takes precedence over the scenario file, but is overridden"
	echo "    by the command line.  Default is config/zathras_specific_vals_def"
	echo "  --java_version: java version to install, java-8, java-11"
	echo "  --kit_upload_directory: Full path to directory uploading to.  If not present, Zathras will locate"
	echo "    the filesystem with the most space on it and use that location."
	echo "  --max_systems <n>:  Maximum number of burden subinstances that will be created from the parent.  Each subinstance"
	echo "    is a cloud or local system. The default is 3."
	echo "  --no_clean_up: Do not cleanup at the end of the test"
	echo "  --no_packages: Do not install any packages. The default is no."
	echo "  --no_pbench_install: Do not install pbench.  The default is 0 (install pbench)"
	echo "  --no_spot_recover: Do not recover from a spot system going away."
	echo "  --package_name <name>: Use this set of packages to override the default in the test config."
	echo "    file instead of the default. Default format  package name <os>_pkg, new name <os>_pkg_<ver>."
	echo "  --pbench_install_stats: level of pbench stats to insall: light, medium, legacy, heavy.  Default is medium."
	echo "        light = vmstat"
	echo "	      medium = vmstat,iostat,sar"
        echo "        heavy = vmstat,iostat,sar,mpstat,perf,pidstat,proc-interrupts,proc-vmstat,turbostat"
	echo "        legacy = iostat,mpstat,perf,pidstat,proc-interrupts,proc-vmstat,sar turbostat"
	echo "  --persistent_log: enable persistent logging"
	echo "  --preflight_check: Performs various checks on the scenario file, and Zathras and then exits"
	echo "  --results_prefix <prefix>: Run directory prefix"
	echo "  --retry_failed_tests 0/1>: Indicates to retry any detected failed tests if set to 1 (1 is the default)."
	echo "  --scenario <scenario definition file>: Reads in a scenario and then runs it"
	echo "    (if used, host configs are designated in the file).  If the scenario name starts with https: or git:"
	echo "    then we are retrieving the scenario from a git repo. If the line in the scenario file starts with #"
	echo "    , then that line is a comment.  If the line starts with a %, it indicates to replace the string."
	echo "    Format to replace a string  % <current string>=<new string>"
	echo "  --scenario_vars <file>: file that contains the variables for the scenario file. The default is config/zathras_scenario_vars_def."
	echo "  --selinux_level: enforcing/permissive/disabled"
	echo "  --selinux_state: disabled/enabled"
	echo "  --ssh_key_file: Designates the ssh key file we are to use."
	echo "  --show_os_versions: given the cloud type, and OS vendor, show the available os versions"
	echo "  --show_tests:  list the available test as defined in config/test_defs.yml"
	echo "  --test_def_file <file>: test definition file to use."
	echo "  --test_def_dir <dir>: test definition directory.  Default is <execution dir>/config.  If"
	echo "     https: or git: is at the start of the location, then we will pull from a git repo."
	echo "  --test_override <options>:  Overrides the given options for a specific test in the scenario file"
	echo "    Example:"
	echo "      global:"
	echo "        ssh_key_file: /home/test_user/permissions/aws_region_2_ssh_key"
	echo "        terminate_cloud: 1"
	echo "        cloud_os_id: aminumber"
	echo "        os_vendor: rhel"
	echo "        results_prefix: linpack"
	echo "        system_type: aws"
	echo "      systems:"
	echo "        system1:"
	echo "          java_version: java-8"
	echo "          tests: linpack"
	echo "          system_type: aws"
	echo "          host_config: \"m5.xlarge\""
	echo "        system2:"
	echo "          java_version: java-8"
	echo "          tests: linpack"
	echo "          system_type: aws"
	echo "          host_config: \"m5.4xlarge\""
	echo "    To override java_version for system1:"
	echo "       --test_override \"system1:java_version=java-11\""
	echo "  --tests <test>: testname, you may use \"test1,test2\" to execute test1 and test2."
	echo "     Note if the option is present, we will ignore all other options passed in."
	echo "  --test_iter <iterations>: how many iterations of the test to run (includes linpack)."
	echo "     For cloud instances, this will terminate the cloud image and start"
	echo "     a new one for each iteration"
	echo "  --test_user <user>:  Name of the user to log into the system with.  The setting of this"
	echo "    option will override the defaults based on cloud or local system."
	echo "  --test_versions <test>,<test>....: Shows the versions of the test the are available"
	echo "    and brief description of the version.  This only applies to git repos"
	echo "  --test_version_check: Checks to see if we are running the latest versions of the tests and"
	echo "    exits out when done. Default is no"
	echo "  --tf_list: list active systems created via tf"
	echo "  --tf_terminate_list <list>: Delete the designated terraform systems."
	echo "  --tf_terminate_all: Go into each terraform directory and attempt to remove the terraform instance"
	echo "  --tuned_profiles <comma separated list of tuned profiles>, only for RHEL.  Designates the tuned"
	echo "    profiles to use.  if the system type is a cloud environment, then each tuned profile is a"
	echo "    distinct cloud instance."
	echo "  --tuned_reboot: reboot when a new tuned is set.  Default is not to reboot"
	echo "  --upload_rpms <rpm 1>,<rpm 2>....: Comma separated list of rpms (full path) to upload and install"
	echo "  --update_target: Image to update"
	echo "    Note:  only 1 update image can be used, makes no difference"
	echo "           if designate a different one for each system in the"
	echo "           scenario file, the first one will be used"
	echo "  --update_test_versions: Will update the templates so we are using the latest versions of the test (git repos only)"
	echo "  --verbose: Verbose usage message"
	echo "  -h --usage: condensed usage information"
	echo "Cloud options only"
	echo "  --cloud_os_id <os id>: Image of the OS to install (example aws aminumber)"
	echo "    For multiple architectures, this is allowed"
	echo "    x86:ami-0fbec8a0a2beb6a71,arm64:ami-0cfa90ca3ebfc506e"
	echo "    Burden will select the right ami for the designated host."
	echo "  --create_only: Only do the VM creation and OS install action."
	echo "  --os_vendor <os vendor>: currently rhel, ubuntu, amazon"
	echo "  --terminate_cloud: If 1, terminate the cloud instance, if 0 leave the cloud image running."
	echo "      Default is to terminate"
	echo "  --use_spot: uses spot pricing based on the contents of config/spot_price.cfg.  Default is not"
	echo "      to use spot_pricing"
	cleanup_and_exit "" 1
}

set_general_value()
{
	shift_by=0
	case "$1" in
		--archive)
			if [[ $gl_archive_location == $value_not_set ]]; then
				gl_archive_location=$2
			fi
			shift_by=2
		;;
		--child)
			if [[ $gl_first_invocation -eq 1 ]]; then
				gl_first_invocation=0
			fi
			shift_by=1
		;;
		--cloud_os_id)
			if [[ $gl_cloud_os_version == "" ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_cloud_os_version=$2
			fi
			shift_by=2
		;;
		--create_attempts)
			echo "$1 $2" >> $gl_cli_supplied_options
			gl_create_attempts=$2
			shift_by=2
		;;
		--create_only)
			if [[ $gl_create_only -eq 0 ]]; then
				echo "$1" >> $gl_cli_supplied_options
				gl_create_only=1
			fi
			#
			# We want to keep the tf around
			#
			if [[ $gl_no_clean_up -eq 0 ]]; then
				echo "--no_clean_up" >> $gl_cli_supplied_options
				gl_no_clean_up=1
			fi
			shift_by=1
		;;
		--dir_index)
			if [[ $gl_run_dir_index -eq 0 ]]; then
				gl_run_dir_index=${2}
			fi
			shift_by=2
		;;
		--force_upload)
			if [[ $gl_cloud_force_upload_set -eq 0 ]]; then
				verify_data verify_force_upload_value $2
				gl_cloud_force_upload_set=1
				gl_cloud_force_upload=1
			fi
			shift_by=1
		;;
		--git_timeout)
			if [[ $gl_git_timeout_set -eq 0 ]]; then
				gl_git_timeout_set=1
				gl_git_timeout=${2}
			fi
			shift_by=2
		;;
 		--host_config)
			echo "$1 $2" >> $gl_cli_supplied_options
			if [[ $gl_host_config == "" ]]; then
				gl_host_config=$2
			fi
			shift_by=2
		;;
		--individ_vars)
			if [[ $gl_zathras_specific_vals_set -eq 0 ]]; then
				gl_zathras_specific_vals=${2}
				gl_zathras_specific_vals_set=1
			fi
			shift_by=2
		;;
		--ignore_repo_errors)
			if [[ $gl_error_repo_errors -eq 1 ]]; then
				echo "$1" >> $gl_cli_supplied_options
				gl_error_repo_errors=0
			fi
			shift_by=1
		;;
		--java_version)
			if [[ $gl_java_version == $value_not_set ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_java_version=$2
				verify_data verify_java_version $2
			fi
			shift_by=2
		;; 
		--kit_upload_directory)
			echo "$1 $2" >> $gl_cli_supplied_options
			gl_kit_upload_directory=$2
			shift_by=2
		;;
		--max_systems)
			if [[ $gl_max_systems_set -eq 0 ]]; then
				gl_max_systems=$2
				gl_max_systems_set=1
			fi
			shift_by=2
		;;
		--no_clean_up)
			if [[ $gl_no_clean_up -eq 0 ]]; then
				echo "$1" >> $gl_cli_supplied_options
				gl_no_clean_up=1
			fi
			shift_by=1
		;;
		--no_packages)
			echo "$1" >> $gl_cli_supplied_options
			gl_no_packages=1
			shift_by=1
		;;
		--no_pbench_install)
			echo "$1 $2" >> $gl_cli_supplied_options
			gl_no_pbench_install=$2
			shift_by=2
		;;
		--no_spot_recover)
			echo "$1" >> $gl_cli_supplied_options
			gl_spot_recover=0
			shift_by=1
		;;
		--os_vendor)
			if [[ $gl_os_vendor == $value_not_set ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_os_vendor=$2
				verify_data verify_os_vendor $2
			fi
			shift_by=2
		;;
		--package_name)
			if [[ $gl_package_name == $value_not_set ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_package_name=$2
			fi
			shift_by=2
		;;
		--pbench_install_stats)
			echo "$1 $2" >> $gl_cli_supplied_options
			gl_pbench_stats=$2
			shift_by=2
		;;
		--persistent_log)
			if [[ $gl_persistent_log -eq 0 ]]; then
				echo "$1" >> $gl_cli_supplied_options
				gl_persistent_log=1
			fi
			shift_by=2
		;;
		--preflight_check)
			gl_preflight=1
			echo "$1" >> $gl_cli_supplied_options
			shift_by=1
		;;
		--results_prefix)
			if [[ $gl_run_prefix == "" ]]; then
				gl_run_prefix=$2
				if [[ -f $gl_run_prefix ]]; then
					cleanup_and_exit "${gl_run_prefix} run directory is actually a file, unable to create a directory of that name" 1
				fi
				echo "${1} $gl_run_prefix" >> $gl_cli_supplied_options
			fi
			shift_by=2
		;;
		--retry_failed_tests)
			gl_retry_failed_tests=$2
			shift_by=2
		;;
		--run_file)
			gl_run_file=$2
			shift_by=2
		;;
		--scenario_vars)
			if [[ $gl_config_vars_file_set -eq 0 ]]; then
				gl_config_vars_file=$2
				gl_config_vars_file_set=1
			fi
			shift_by=2
		;;
		--show_tests)
			gl_test_version_check=0
			gl_show_tests=1
			shift_by=1
		;;
		--scenario)
			#
			# Scenario request
			#
			if [[ $gl_scenario_to_run == "" ]]; then
				gl_scenario_to_run=$2
			fi
			shift_by=2
		;;
		--selinux_level)
			gl_selinux_level=$2
			echo "$1 $gl_selinux_level" >> $gl_cli_supplied_options
			verify_data verify_selinux_level $gl_selinux_level
			shift_by=2
		;;
		--selinux_state)
			gl_selinux_state_set=1
			gl_selinux_state=$2
			echo "$1 $gl_selinux_state" >> $gl_cli_supplied_options
			verify_data verify_selinux_state $gl_selinux_state
			shift_by=2
		;;
		--show_os_versions)
			gl_show_os_versions=1
			shift_by=1
		;;
		--ssh_key_file)
			if [[ $gl_ssh_key_file == "" ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_ssh_key_file=$2
				verify_data verify_ssh_key_file $gl_ssh_key_file
			fi
			shift_by=2
		;;
		--system_type)
			if [[ $gl_system_type == "" ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
 				gl_system_type=$2
				verify_data verify_system_type $gl_system_type
			fi
			shift_by=2
 		;;
		--terminate_cloud)
			if [[ $gl_cloud_terminate_instance_set -eq 0 ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_cloud_terminate_instance=$2
				verify_data verify_terminate_value $2
				gl_cloud_terminate_instance_set=0
			fi
			shift_by=2
		;;
		--test_def_dir)
			if [[ $gl_test_def_dir_set -eq 0 ]]; then
				gl_test_def_dir_set=1
				gl_test_def_dir=$2
			fi
			shift_by=2
		;;
		--test_def_file)
			if [[ $gl_test_def_file == "" ]]; then
				gl_test_def_file=$2
			fi
			shift_by=2
		;;
		--test_iter)
			if [[ $gl_test_iterations_set -eq 0 ]]; then
				gl_test_iterations_set=1
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_test_iterations=$2
				verify_data verify_iterations $2
			fi
			shift_by=2
		;;
		--test_override)
			#
			# We accumulate these across the various files.
			#
			if [[ $gl_test_override_options != "" ]]; then
				gl_test_override_options="${gl_test_override_options} "${2}
			else
				gl_test_override_options=$2
			fi
			shift_by=2
		;;
		--test_version_check)
			shift_by=1
		;;
		--test_user)
			echo "$1 $2" >> $gl_cli_supplied_options
			gl_test_user=$2
			shift_by=2
		;;
		--test_versions)
			#
			# Does not return
			#
			show_test_version $2 
		;;
		--tests)
			if [[ $gl_test_list == "" ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
 				gl_test_list=$2
				verify_test $2
				gl_test_list_out=$gl_test_list_out$gl_test_list
			fi
			shift_by=2
 		;;
		--tf_list)
			gl_tf_list=1
			shift_by=1
		;;
		--tf_terminate_all)
			gl_tf_terminate=1
			shift_by=1
		;;
		--tf_terminate_list)
			gl_tf_terminate=1
			gl_tf_term_list=$2
			shift_by=2
		;;
		--tuned_profiles)
			if [[ $gl_rhel_tuned_setting == $value_not_set ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_rhel_tuned_setting=$2
			fi
			shift_by=2
		;;
		--tuned_reboot)
			gl_rhel_tuned_reboot=$2
			shift_by=2
		;;
		--update_target)
			if [[ $gl_update_target == $value_not_set ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_update_target=$2
			fi
			shift_by=2
		;;
		--update_test_versions)
			gl_update_test_versions=1
			shift_by=1
		;;
		--upload_rpms)
			if [[ $gl_upload_rpms == $value_not_set ]]; then
				echo "$1 $2" >> $gl_cli_supplied_options
				gl_upload_rpms=$2
			fi
			shift_by=2
		;;
		--usage)
			usage "0"
			shift_by=1
		;;
		--use_spot)
			gl_use_spot=$2
			shift_by=2
		;;
		--verbose)
			usage "1"
			shift_by=1
		;;
		-h)
			usage "0"
			shift_by=1
		;;
		--)
			shift_by=1
		;;
		*)
			echo "not found $1"
			usage "0"
		;;
	esac
	return $shift_by
}

grab_cli_data()
{
	#
	# Define user options
	#
	ARGUMENT_LIST=(
		"archive"
		"cloud_os_id"
		"create_attempts"
		"dir_index"
		"git_timeout"
		"host_config"
		"individ_vars"
		"java_version"
		"kit_upload_directory"
		"max_systems"
		"os_vendor"
		"package_name"
		"no_pbench_install"
		"pbench_install_stats"
		"results_prefix"
		"retry_failed_tests"
		"run_file"
		"scenario"
		"ssh_key_file"
		"tuned_profiles"
		"scenario_vars"
		"selinux_level"
		"selinux_state"
		"system_type"
		"terminate_cloud"
		"test_iter"
		"tests"
		"test_def_dir"
		"test_def_file"
		"test_override"
		"test_user"
		"test_versions"
		"tf_terminate_list"
		"tuned_reboot"
		"update_target"
		"upload_rpms"
		"use_spot"
	)

	NO_ARGUMENTS=(
		"child"
		"create_only"
		"force_upload"
		"ignore_repo_errors"
		"no_clean_up"
		"no_packages"
		"no_spot_recover"
		"persistent_log"
		"preflight_check"
		"show_os_versions"
		"show_tests"
		"test_version_check"
		"tf_list"
		"tf_terminate_all"
		"update_test_versions"
		"usage"
		"verbose"
	)

	# read arguments
	opts=$(getopt \
	    --longoptions "$(printf "%s:," "${ARGUMENT_LIST[@]}")" \
	    --longoptions "$(printf "%s," "${NO_ARGUMENTS[@]}")" \
	    --name "$(basename "$0")" \
	    --options "h" \
	    -- "$@"
	)

	if [[ $? -ne 0 ]]; then
		usage "0"
	fi

	eval set --$opts

	gl_cli_supplied_options=`mktemp /tmp/zathras.XXXXX`

	#
	# If no options provided, then usage message.
	# 
	if [ $# -eq 1 ]; then
		usage "0"
	fi

	while [[ $# -gt 0 ]]; do
		set_general_value $1 $2
		shift $?
	done
}

check_for_scen_value()
{
	grep "$1" $2 >2 /dev/null
	if [ $? -ne 0 ]; then
		cleanup_and_exit "Scenario file "$2": missing $1" 1
	fi
}

scenario_file_sanity()
{
	check_for_scen_value "^systems:" $1
	check_for_scen_value "^global:" $1
	check_for_scen_value "^    tests:" $1
	check_for_scen_value "^    host_config:" $1
}

add_test_to_file()
{
	system=$1
	test=$2
	new_scen_file=$3

	if [ $gl_sys_index_rerun -ne 1 ]; then
		echo "  system${gl_sys_index_rerun}:" >> $new_scen_file
		echo "    host_config: \"SYS_BARRIER\"" >> $new_scen_file
		let "gl_sys_index_rerun=$gl_sys_index_rerun+1"
	fi
	echo "  system$gl_sys_index_rerun:" >> $new_scen_file
	let "gl_sys_index_rerun=$gl_sys_index_rerun+1"
	while IFS= read -r test_info
	do
		if [[ "$test_info" == "tests:"* ]]; then
			echo "    tests: $test" >> $new_scen_file
			continue
		fi
		if [[ "$test_info" == "host_config:"* ]]; then
			echo "    host_config: $system" >> $new_scen_file
			continue
		fi
			echo "    $test_info" >> $new_scen_file
	done < "new_info"
}

check_for_test()
{
	system=$1
	test_list=$2
	new_scen_file=$3

	grep -q $system new_info
	if [ $? -eq 0 ]; then
		for test in $test_list; do
			grep -q $test new_info
			if [ $? -eq 0 ]; then
				add_test_to_file $system $test $new_scen_file
			fi
		done
	fi
}

add_missing_test()
{
	system=$1
	test=$2
	new_scenario=$4
	scenario_file=$3
	start_of_test_found=0
	test_section_start=0
	test_section=0
	while IFS= read -r test_info
	do
		if [ $start_of_test_found -eq 0 ]; then
			if [[ $test_info  == "systems:"* ]]; then
				start_of_test_found=1
			fi
			continue
		fi
		if [[ $test_info == "  system"* ]];then
			if [ $test_section_start -eq 1 ]; then
				check_for_test  $system "$test" $new_scen_file
				rm new_info 2> /dev/null
			fi
			test_section_start=1
			continue
		fi
		echo $test_info >> new_info
	done < $scenario_file
	if [[ -f new_info ]]; then
		check_for_test  $system "$test" $new_scen_file
		rm new_info 2> /dev/null
	fi
}

handle_error_reruns()
{
	scenario_to_run=${gl_top_dir}/${gl_scenario_to_run}_fix
	#
	# Replace all +++ in the scenario file
	#
	sed "s/+++/\//g" ${gl_top_dir}/${gl_scenario_to_run} > $scenario_to_run

	new_scen_file=${scenario_to_run}_rerun
	rm $new_scen_file 2> /dev/null
	gl_sys_index_rerun=1

	#
	# First get all the headers
	#
	while IFS= read -r test_info
	do
		if [[ $test_info  == "systems:"* ]]; then
			echo $test_info >> $new_scen_file
			break
		fi
		if [[ $test_info != *"use_spot:"* ]]; then
			echo "$test_info" >> $new_scen_file
		fi
	done < "${scenario_to_run}"

	while IFS= read -r bad_test
	do
		system=`echo $bad_test | cut -d':'  -f 2`
		test=`echo $bad_test | cut -d':'  -f 3`
		add_missing_test $system "$test" $scenario_to_run $new_scen_file $scenario_to_run
	done < test_errors
	#
	# If we have spot failures, handle them here.
	# We will not run spot on any test failure, it simplifies
	# having to deal with spot but test failed vs spot failure.
	# We have already removed the spot request in the scenario file.
	#
	rm */spot_failure
	pushd $gl_top_dir > /dev/null
	./burden --scenario  $new_scen_file --retry_failed_tests 0
	popd > /dev/null
}

grab_vars_data()
{
	if [[ $gl_first_invocation -eq 1 ]]; then
		if [[ -f $gl_zathras_specific_vals ]]; then
			while IFS= read -r line
			do
				option_setting=`echo ${line} | cut -d':' -f1`
				value_setting=`echo ${line} | cut -d':' -f2- | sed "s/ //g"`
				set_general_value "--${option_setting}" "${value_setting}"
			done < "$gl_zathras_specific_vals"
		else
			if [[ $gl_zathras_specific_vals_set -ne 0 ]]; then
				cleanup_and_exit "You designated ${gl_zathras_specific_vals} for specific values, but file does not exist, aborting" 1
			fi
		fi
	fi
}

first_invocation()
{
	if [[ ! -f $gl_config_vars_file ]] && [[ $gl_config_vars_file_set -eq 1 ]]; then
		cleanup_and_exit "\nError: Designated the vars file $gl_config_vars_file which can not be found" 1
	fi
	if [[ $gl_config_vars_file != "" ]]; then
		if [[ -f $gl_config_vars_file ]]; then
			lines_in_vars_file=`wc -l ${gl_config_vars_file} | cut -d' ' -f 1`
		else
			lines_in_vars_file=0
		fi
	fi
	if [[ -f $gl_config_vars_file ]] && [[ $lines_in_vars_file != "0" ]]; then
		if [[ -z $gl_system_type ]]; then
			cleanup_and_exit "\nError: Need to designate the system type \(--system_type\) when using n-config_vars." 1
		fi
		# Save a copy of the scenario file.
		#
		gl_scenario_to_restore=${gl_scenario_to_run}.restore
		cp $gl_scenario_to_run $gl_scenario_to_restore
		tfile=`mktemp /tmp/zathras_out_file.XXXXX`
		cfile=`mktemp /tmp/zathras_out_file.XXXXX`
		#
		# We will replace the <system_type>_ with "".
		#
		sed "s/^${gl_system_type}_//g" $gl_config_vars_file > $cfile
		#
		#
		# Read the config file in.
		#
		gl_moved_scenario=`pwd`
		#
		# First system type
		#
		sed "s/\[cloud_type\]/${gl_system_type}/g" $gl_scenario_to_run > $tfile
		mv $tfile $gl_scenario_to_run
		#
		# Now the other fields
		#
		while IFS= read -r line
		do
			line1=`echo "$line" | sed "s/&/_____/g"`
			line=$line1
			field_name=`echo $line | cut -d':' -f 1`
			#
			# Replace any / with ####, makes sed eaiser to deal with on
			# ssh key paths.
			#
			field_value=`echo $line | cut -d':' -f 2- | sed "s/ //g" | sed "s/\//####/g"`
			sed "s/\[${field_name}\]/${field_value}/g" $gl_scenario_to_run > $tfile
			mv $tfile $gl_scenario_to_run
		done < "$cfile"
		#
		# Replace #### with /
		#
		sed "s/####/\//g" $gl_scenario_to_run | sed "s/_____/\&/g" > $tfile
		mv $tfile $gl_scenario_to_run
		rm $cfile
	fi
	rm test_info 2> /dev/null
	rm java_info 2> /dev/null

	if [[ $gl_scenario_to_run != "" ]]; then
		test_def_info=`grep "^  test_def_dir:" ${gl_scenario_to_run}`
		if [[ $? -eq 0 ]]; then
			#
			# Use the value provided
			#
			if [[ ${test_def_info} == *"https:"* ]] || [[ "${gl_scenario_to_run}" == *"git:"* ]]; then
				git_area=`echo $test_def_info | cut -d':' -f 2- | sed "s/ //g"`
				#
				# Pulling from git
				#
				rm -rf config_git 2> /dev/null
				timeout $gl_git_timeout git clone ${git_area} config_git 2> /dev/null
				if [[ $? -ne  0 ]]; then
					cleanup_and_exit "\nError: retrieval of git repo $git_area has failed." 1
				fi
				gl_test_def_dir=`pwd`/config_git
			else
				gl_test_def_dir=`echo $test_def_info | cut -d':' -f 2 | sed "s/ //g"`
			fi
		fi
	fi
	if [[ $gl_scenario_to_run != "" ]]; then
		#
		# Need to make sure the lines do not get to big.
		#
		gl_scenario_to_run=`$UTILS_DIR/brk_up_large_scn_host_configs --scenario $gl_scenario_to_run`
		if [ $? -ne 0 ]; then
			cleanup_and_exit "Break up of scenario file failed" 1
		fi
		fields=`grep "\[" ${gl_scenario_to_run}`
		if [[ $fields != "" ]]; then
			cleanup_and_exit "Error: following fields in ${gl_scenario_to_run} has no entry in ${gl_config_vars_file}:\n${fields}" 1
		fi
		if [[ ! -f ${gl_test_def_dir}/test_defs.yml ]]; then
			cleanup_and_exit "Error: ${gl_test_def_dir}/test_defs.yml does not exist" 1
		fi
	fi

	integrate_templates ${gl_test_def_dir}/test_defs.yml
	cat $gl_test_def_dir/full_test_defs.yml | yq . > test_info
	cat $gl_test_def_dir/java_pkg_def.yml | yq . > java_info
}

cli_data="$@"
grab_cli_data "$@"
grab_vars_data
if [[ $gl_scenario_to_run != "" ]]; then
	replace_scenario_vars
fi
#
# Does not return
#
if [ $gl_tf_terminate -eq 1 ]; then
	tf_terminate
fi

#
# Does not return
#
if [ $gl_tf_list -eq 1 ]; then
	tf_list
fi

if [[ $gl_run_prefix == "" ]]; then
	gl_run_prefix=`id -un`
fi

if [[ $gl_host_config != "" ]]; then
	verify_data verify_host_config $gl_host_config
fi

#
# check to make sure the packages that are required are installed.
#
if [[ $gl_first_invocation -eq 1 ]]; then
	rm utils_version run_info 2> /dev/null
	package_check
fi

#
# Retrieve the test_def config if need be or verify it is present.
#

if [[ $gl_test_def_file == "" ]]; then
	handle_test_defs
else
	chars=`echo ${gl_test_def_file} | awk -v RS='/' 'END{print NR-1}'`
	gl_test_def_dir=`echo ${gl_test_def_file} | cut -d'/' -f 1-${chars}`

fi

#
# Are we looking up the cloud images?
#
if [[ $gl_show_os_versions -eq 1 ]]; then
	if [[ -z $gl_os_vendor ]]; then
		cleanup_and_exit "You need to designate an OS vendor via --os_vendor argument. Valid OS vendors are $gl_valid_os_vendors" 1
	fi
	if [[ -z $gl_system_type ]]; then
		cleanup_and_exit "You need to designate the cloud vendor via --system_type argument. Valid systems types are $gl_valid_system_types " 1
	fi
	#
	# Obtain the possible cloud images.
	#
	cloud_image_lookup
	cleanup_and_exit "" 0
fi

verify_selinux

#
# Retrieve the scenario file if need be.
#
if [[ "${gl_scenario_to_run}" == *"https:"* ]] || [[ "${gl_scenario_to_run}" == *"git:"* ]]; then
	#
	# Request to get scenario from a git repo.
	#
	chars=`echo ${gl_scenario_to_run} | awk -v RS='/' 'END{print NR-1}'`
	git_area=`echo ${gl_scenario_to_run} | cut -d'/' -f 1-${chars}`
	#
	# Pulling from git
	#
	rm -rf scenarios 2> /dev/null
	timeout $gl_git_timeout git clone ${git_area} scenarios 2> /dev/null
	if [[ $? -ne  0 ]]; then
		cleanup_and_exit "\nError: retrieval of git repo $git_area has failed." 1
	fi
	let "chars=${chars}+1"
	scen_file=`echo ${gl_scenario_to_run} | cut -d'/' -f ${chars}`
	gl_scenario_to_run=`pwd`/scenarios/${scen_file}
fi

#
# Set up the various config files, if everything is started from this 
# process.
#
if [[ $gl_scenario_to_run != "" ]]; then
	if [[ $gl_first_invocation -eq 1 ]]; then
		#
		# Sanity check scenario file
		#
		scenario_file_sanity $gl_scenario_to_run
		first_invocation
	else
	#
	# A bit of sanity check.
	#
		if [[ -z "$gl_host_config" ]] || [[ -z "$gl_system_type" ]]; then
			echo "missing one of these"
			echo "host_config: $gl_host_config"
			echo "gl_system_type: $gl_system_type"
			usage "0"
		fi
	fi
else
	first_invocation
fi

# If a scenario is designated, then run it.
#
if [[ $gl_scenario_to_run != "" ]]; then
        run_scenario $gl_scenario_to_run
	process_results
        cleanup_and_exit "" 0
fi

#
# List the available tests.
#
if [[ $gl_show_tests -eq 1 ]]; then
	#
	# Does not return
	#
	list_tests_available
fi

#
# If the user has asked to create the system only, do not execute any tests
# and do not terminate the system.
#
if [[ $gl_create_only -eq 1 ]]; then
	gl_cloud_terminate_instance=0
	gl_cloud_execute_tests=0
fi

#
# System update is only supported for RHEL
#
if [[ $gl_update_target != $value_not_set ]] &&  [[ $gl_os_vendor != "rhel" ]]; then
	cleanup_and_exit "Updating ${gl_os_vendor} is not supported at this time, bailing out" 1
fi

#
# Are we looking up the cloud images?
#
if [[ $gl_show_os_versions -eq 1 ]]; then
	if [[ -z $gl_os_vendor ]]; then
		cleanup_and_exit "You need to designate an os vendor" 1
	fi
	if [[ -z $gl_system_type ]]; then
		cleanup_and_exit "You need to designate who is providing the cloud image" 1
	fi
	#
	# Obtain the possible cloud images. Does not return
	#
	cloud_image_lookup
fi

#
# Do the general setup.
#
general_setup $test_def_info

#
# List of tests to run
#
gl_test_list_out=$gl_test_list

#
# Update the OS image if a target is designated.
#
if [[ $gl_update_target != $value_not_set ]]; then
	update_the_image $gl_update_target
fi

#
# Replace ',' with ' '
#
config=${gl_host_config//,/ }

#
# Go and do the work.
#
create_ansible_options

#
# Remove names from known host file
#

remove_hostnames_added

if [[ $gl_warning_string != "" ]]; then
	echo -e $gl_warning_string
fi

#
# Ok, go back through things and perfrom any runs related to spot failirues or other such things.
# We try only once.
#

process_results
popd > /dev/null
cleanup_and_exit "" 0
